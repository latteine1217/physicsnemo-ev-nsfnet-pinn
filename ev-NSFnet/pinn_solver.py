# Copyright (c) 2023 scien42.tech, Se42 Authors. All Rights Reserved.
#
        
        
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# Author: Zhicheng Wang, Hui Xiang
# Created: 08.03.2023
import os
import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import TensorDataset, DataLoader, DistributedSampler
from torch.utils.tensorboard import SummaryWriter
import scipy.io
import numpy as np
import math
from net import FCNet
from laaf import LAAFScalar, compute_laaf_regularization
from tools import setup_device, get_cuda_info
from typing import Dict, List, Set, Optional, Union, Callable, Any, Tuple
import warnings
import time
import datetime
from logger import LoggerFactory, PINNLogger
from torch.nn import Module
from torch import Tensor
# from health_monitor import TrainingHealthMonitor, HealthThresholds
# from memory_manager import TrainingMemoryManager



# æŠ‘åˆ¶ PyTorch åˆ†æ•£å¼è¨“ç·´çš„ autograd è­¦å‘Š
warnings.filterwarnings("ignore", message=".*c10d::allreduce_.*autograd kernel.*")

class PysicsInformedNeuralNetwork:
    # é¡å‹è¨»è§£
    net: Union[FCNet, DDP]
    net_1: Union[FCNet, DDP]
    device: torch.device
    logger: PINNLogger
    tb_writer: Optional[SummaryWriter]
    x_f: Optional[Tensor]
    y_f: Optional[Tensor]
    x_b: Optional[Tensor]
    y_b: Optional[Tensor]
    x_i: Optional[Tensor]
    y_i: Optional[Tensor]
    x_o: Optional[Tensor]
    y_o: Optional[Tensor]
    opt: Optional[torch.optim.Optimizer]
    opt_1: Optional[torch.optim.Optimizer]
    
    def _param_name_map(self, model: Union[Module, DDP]) -> Dict[int, str]:
        return {id(p): n for n, p in model.named_parameters()}

    def _safe_optimizer_state_dict(self, optimizer: torch.optim.Optimizer) -> Dict[str, Any]:
        try:
            state = optimizer.state
            param_ids = set(id(p) for g in optimizer.param_groups for p in g.get('params', []))
            safe_state = {}
            for k, v in state.items():
                if k in param_ids:
                    safe_state[k] = v
            pg = []
            for g in optimizer.param_groups:
                pg.append({k: v for k, v in g.items() if k != 'params'})
            return {'state': safe_state, 'param_groups': pg}
        except Exception:
            return {}

    def _load_optimizer_state_dict_safe(self, optimizer: torch.optim.Optimizer, opt_state: Optional[Dict[str, Any]]) -> None:
        try:
            if not opt_state:
                return
            optimizer.load_state_dict(opt_state)
            for state in optimizer.state.values():
                for k, v in list(state.items()):
                    if isinstance(v, torch.Tensor):
                        state[k] = v.to(self.device)
        except Exception:
            pass
    # Initialize the class
    def __init__(self,
                 opt=None,
                 Re = 1000,
                 layers=6,
                 layers_1=4,
                 hidden_size=80,
                 hidden_size_1=40,
                 N_f = 100000,
                 batch_size = None,
                 alpha_evm=0.03,
                 learning_rate=0.001,
                 outlet_weight=1,
                 bc_weight=10,
                 eq_weight=1,
                 ic_weight=0.1,
                 num_ins=2,
                 num_outs=3,
                 num_outs_1=1,
                 supervised_data_weight=1,
                 supervision_data_points=0,
                 supervision_data_path=None,
                 supervision_random_seed=42,
                 net_params=None,
                 net_params_1=None,
                 checkpoint_freq=2000,
                 config=None):
        # Initialize distributed training identifiers first
        self.rank = int(os.environ.get('RANK', 0))
        self.local_rank = int(os.environ.get('LOCAL_RANK', 0))
        self.world_size = int(os.environ.get('WORLD_SIZE', 1))

        # Initialize logger ASAP to avoid use-before-init warnings
        self.logger = LoggerFactory.get_logger(
            name=f"PINN_Re{Re}",
            level="INFO",
            rank=self.rank
        )

        # ä½¿ç”¨çµ±ä¸€è¨­å‚™ç®¡ç†å‡½æ•¸
        self.device = setup_device(self.local_rank, self.logger)

        self.evm = None
        self.Re = Re
        self.vis_t0 = 20.0/self.Re
        self.beta = None

        self.layers = layers
        self.layers_1 = layers_1
        self.hidden_size = hidden_size
        self.hidden_size_1 = hidden_size_1
        self.N_f = N_f
        self.batch_size = batch_size if batch_size is not None else N_f
        self.current_stage = ' '

        self.checkpoint_freq = checkpoint_freq
        # æç¤ºæ§åˆ¶
        self._tips_last_step = {}
        self.prev_strategy_step = -10**9

        # TensorBoardè¨­å®šï¼ˆæ”¯æ´é »ç‡æ§åˆ¶èˆ‡å¯é—œé–‰ï¼‰
        sys_cfg = getattr(self, 'config', None)
        sys_cfg = getattr(sys_cfg, 'system', None) if sys_cfg is not None else None
        tb_enabled = bool(getattr(sys_cfg, 'tensorboard_enabled', True)) if sys_cfg is not None else True
        self.tb_interval = int(getattr(sys_cfg, 'tensorboard_interval', 1000)) if sys_cfg is not None else 1000
        if self.rank == 0 and tb_enabled:
            log_dir = f"runs/NSFnet_Re{Re}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.tb_writer = SummaryWriter(log_dir=log_dir)
            self.logger.info(f"ğŸ“Š TensorBoard log directory: {log_dir} (interval={self.tb_interval})")
        else:
            self.tb_writer = None

        # æ™‚é–“è¿½è¹¤ç›¸é—œè®Šæ•¸
        self.epoch_start_time = None
        self.epoch_times = []
        self.stage_start_time = None
        self.training_start_time = None
        self.global_step_offset = 0  # ç”¨æ–¼è¨ˆç®—è·¨éšæ®µçš„global step

        # å¥åº·ç›£æ§ç³»çµ±
        self.health_monitor = None
        self.memory_manager = None

        self.alpha_evm = alpha_evm
        self.alpha_b = bc_weight
        self.alpha_e = eq_weight
        self.alpha_i = ic_weight
        self.alpha_o = outlet_weight
        self.alpha_s = supervised_data_weight
        self.loss_i = self.loss_o = self.loss_b = self.loss_e = self.loss_s = 0.0

        # ç›‘ç£æ•°æ®å‚æ•°
        self.supervision_data_points = supervision_data_points
        self.supervision_data_path = supervision_data_path
        self.supervision_random_seed = supervision_random_seed
        
        # ç›‘ç£æ•°æ®å­˜å‚¨å˜é‡ (å°†åœ¨æ•°æ®åŠ è½½æ—¶åˆå§‹åŒ–)
        self.x_sup = None
        self.y_sup = None
        self.u_sup = None
        self.v_sup = None  
        self.p_sup = None

        # Persist config early for post-init scaling, if provided
        self.config = config if config is not None else getattr(self, 'config', None)

        # initialize NN
        self.net = self.initialize_NN(
                num_ins=num_ins, num_outs=num_outs, num_layers=layers, hidden_size=hidden_size, is_evm=False).to(self.device)
        self.net_1 = self.initialize_NN(
                num_ins=num_ins, num_outs=num_outs_1, num_layers=layers_1, hidden_size=hidden_size_1, is_evm=True).to(self.device)

        

        # ç¢ºä¿æ‰€æœ‰å¼µé‡ä½¿ç”¨ float32 ç²¾åº¦
        self.net = self.net.float()
        self.net_1 = self.net_1.float()

        # åœ¨DDPåŒ…è£¹ä¹‹å‰ä¾é…ç½®æ–½åŠ é¦–/æœ«å±¤ç¸®æ”¾ï¼Œé¿å…è·¨rankæ¬Šé‡å·®ç•°
        self.apply_config_post_init()

        # å„ªåŒ–ï¼šåˆå§‹åŒ–vis_tç›¸é—œè®Šæ•¸ï¼Œé¿å…é‡è¤‡æª¢æŸ¥
        self.vis_t_minus_gpu = None  # GPUç‰ˆæœ¬çš„vis_t_minus

        # Wrap models with DDP only if in distributed mode
        if self.world_size > 1:
            # å¾é…ç½®è®€å– DDP broadcast_buffers åˆ‡æ›ï¼ˆé è¨­ Falseï¼‰
            ddp_broadcast_buffers = False
            if self.config is not None and hasattr(self.config, 'system'):
                try:
                    ddp_broadcast_buffers = bool(getattr(self.config.system, 'ddp_broadcast_buffers', False))
                except Exception:
                    ddp_broadcast_buffers = False
            # å›ºå®šå‰å‘è·¯å¾‘ä»¥é—œé–‰æœªç”¨åƒæ•¸æƒæ
            self.net = DDP(self.net, 
                           device_ids=[self.local_rank], 
                           output_device=self.local_rank,
                           find_unused_parameters=False,                           
                           broadcast_buffers=ddp_broadcast_buffers,        # å¯é…ç½®çš„bufferåŒæ­¥
                           gradient_as_bucket_view=True)  # æå‡è¨˜æ†¶é«”æ•ˆç‡
            self.net_1 = DDP(self.net_1, 
                             device_ids=[self.local_rank], 
                             output_device=self.local_rank,
                             find_unused_parameters=False,                             
                             broadcast_buffers=ddp_broadcast_buffers,        # å¯é…ç½®çš„bufferåŒæ­¥
                             gradient_as_bucket_view=True)  # æå‡è¨˜æ†¶é«”æ•ˆç‡

        if net_params:
            self.logger.info(f"Loading net params from {net_params}")
            self.load(net_params)

        # é¡¯ç¤ºåˆ†å¸ƒå¼è¨“ç·´ä¿¡æ¯
        self.logger.info("Distributed training setup:")
        self.logger.info(f"  World size: {self.world_size}")
        self.logger.info(f"  Rank: {self.rank}")
        self.logger.info(f"  Local rank: {self.local_rank}")

        # è¼¸å‡ºåˆå§‹åŒ–ä¿¡æ¯
        config_info = {
            "Reynoldsæ•¸": self.Re,
            "ä¸»ç¶²è·¯": f"{self.layers} å±¤ Ã— {self.hidden_size} ç¥ç¶“å…ƒ",
            "EVMç¶²è·¯": f"{self.layers_1} å±¤ Ã— {self.hidden_size_1} ç¥ç¶“å…ƒ",
            "è¨“ç·´é»æ•¸": f"{self.N_f:,}",
            "è¨­å‚™": str(self.device),
            "æ‰¹æ¬¡å¤§å°": "å…¨æ‰¹æ¬¡" if self.batch_size == self.N_f else str(self.batch_size)
        }
        self.logger.system_info(config_info)

    # ========= Config-driven setup helpers =========
    def _apply_layer_scales(self, model: torch.nn.Module, first_scale: float, last_scale: float) -> None:
        """Apply scaling to the first and last Linear layers' weights.

        This should be called after Xavier init and is deterministic across ranks
        when executed on each process.
        """
        linear_layers = [m for m in model.modules() if isinstance(m, torch.nn.Linear)]
        if not linear_layers:
            return
        # é¦–å±¤
        linear_layers[0].weight.data.mul_(float(first_scale))
        # æœ«å±¤
        linear_layers[-1].weight.data.mul_(float(last_scale))

    def apply_config_post_init(self) -> None:
        """Apply configuration-dependent behaviors after construction.

        - Layer scaling for main/EVM nets
        """
        cfg = getattr(self, 'config', None)
        if cfg is None:
            return
        # è®€å–ç¸®æ”¾å› å­ï¼ˆè‹¥ç¼ºçœå‰‡æ¡ç”¨é è¨­ï¼‰
        ncfg = cfg.network
        try:
            main_first = float(getattr(ncfg, 'first_layer_scale_main', 2.0))
            main_last = float(getattr(ncfg, 'last_layer_scale_main', 0.5))
            evm_first = float(getattr(ncfg, 'first_layer_scale_evm', 1.2))
            evm_last = float(getattr(ncfg, 'last_layer_scale_evm', 0.1))
        except Exception:
            main_first, main_last, evm_first, evm_last = 2.0, 0.5, 1.2, 0.1

        # å°åº•å±¤æ¨¡å‹æ“ä½œï¼ˆå…¼å®¹DDPï¼‰
        main_model = self.get_model(self.net)
        evm_model = self.get_model(self.net_1)
        self._apply_layer_scales(main_model, main_first, main_last)
        self._apply_layer_scales(evm_model, evm_first, evm_last)

    def get_model_parameters(self, model):
        """Get model parameters considering DDP wrapper"""
        if hasattr(model, 'module'):
            return model.module.parameters()
        else:
            return model.parameters()

    def get_model(self, model: Union[FCNet, DDP]) -> FCNet:
        """Get underlying model considering DDP wrapper"""
        if isinstance(model, DDP):
            return model.module
        else:
            return model

    def get_checkpoint_dir(self):
        """Generates the directory path for saving checkpoints and results."""
        Re_folder = f'Re{self.Re}'
        # Ensure integer conversion for folder names
        n_f_k = int(self.N_f / 1000)
        
        # Format stage name for path
        stage_name = self.current_stage.replace(' ', '_')

        nn_size = f'{self.layers}x{self.hidden_size}_Nf{n_f_k}k'
        params = f'lamB{int(self.alpha_b)}_alpha{self.alpha_evm}{stage_name}'
        
        # Use os.path.join for robust path construction
        base_path = os.path.expanduser('~/NSFnet/ev-NSFnet/results')
        return os.path.join(base_path, Re_folder, f"{nn_size}_{params}")

    def save_checkpoint(self, epoch, optimizer):
        """Saves a comprehensive checkpoint."""
        if self.rank != 0:
            return

        checkpoint_dir = self.get_checkpoint_dir()
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')
        
        # Ensure we are saving the underlying model state
        net_state = self.get_model(self.net).state_dict()
        net_1_state = self.get_model(self.net_1).state_dict()

        # è§£æ±º torch.compile åœ¨å„²å­˜ optimizer state dict æ™‚çš„ KeyError
        # ç›´æ¥èª¿ç”¨åŸºé¡çš„æ–¹æ³•ä»¥ç¹éç·¨è­¯å¾Œçš„å‡½æ•¸
        checkpoint = {
            'epoch': epoch,
            'net_state_dict': net_state,
            'net_1_state_dict': net_1_state,
            # safe optimizer state_dict to avoid KeyError when params changed
            'optimizer_state_dict': self._safe_optimizer_state_dict(optimizer),
            'Re': self.Re,
            'alpha_evm': self.alpha_evm,
            'current_stage': self.current_stage,
            'global_step_offset': self.global_step_offset,
            'current_weight_decay': getattr(self, 'current_weight_decay', 0.0)
        }

        try:
            torch.save(checkpoint, checkpoint_path)
            self.logger.checkpoint_saved(checkpoint_path, epoch)
        except Exception as e:
            self.logger.error(f"Failed to save checkpoint to {checkpoint_path}: {e}")

    def load_checkpoint(self, checkpoint_path, optimizer):
        """Loads a checkpoint to resume training with optimizer structure auto-repair.

        å¢å¼·å…§å®¹:
        1. è‡ªå‹•æª¢æŸ¥ optimizer.param_groups çµæ§‹æ˜¯å¦ç¬¦åˆ AdamW(decay + nodecay) è¦ç¯„
        2. è‹¥æª¢æ¸¬åˆ° legacy / ä¸ä¸€è‡´çµæ§‹ â†’ ä¾ç…§ä¿å­˜çš„ current_weight_decay é‡å»º
        3. å˜—è©¦å°‡èˆŠ state ä¸­çš„ exp_avg / exp_avg_sq / step é·ç§»è‡³æ–°åƒæ•¸ (ä»¥ id åŒ¹é…)
        4. è‹¥é·ç§»å¤±æ•—ä¸çµ‚æ­¢ï¼Œè¨˜éŒ„è­¦å‘Šä¸¦ä»¥æ–°ç‹€æ…‹ç¹¼çºŒ
        """
        def _needs_rebuild(opt: torch.optim.Optimizer) -> bool:
            try:
                if opt is None or not opt.param_groups:
                    return True
                # è¦ç¯„: 1~2 groups; è‹¥ >2 ä»£è¡¨èˆŠæ ¼å¼æˆ–æ‰‹å‹• group
                if len(opt.param_groups) > 2:
                    return True
                # è‹¥åªæœ‰1çµ„ä½† weight_decay=0 ä¸”å­˜åœ¨å¯ decay åƒæ•¸ â†’ å…è¨±, ä½†ä¸å¼·åˆ¶é‡å»º
                # é©—è­‰ group æ¬„ä½å®Œæ•´æ€§
                for g in opt.param_groups:
                    if 'params' not in g:
                        return True
                return False
            except Exception:
                return True
        def _migrate_state(old_state: dict, new_opt: torch.optim.Optimizer):
            try:
                # old_state: optimizer.state (k=id(param))
                if not old_state:
                    return 0,0
                transferred = 0
                skipped = 0
                new_param_ids = {id(p): p for pg in new_opt.param_groups for p in pg['params']}
                for pid, s in old_state.items():
                    if pid in new_param_ids:
                        try:
                            new_state_slot = new_opt.state[new_param_ids[pid]]
                            for k,v in s.items():
                                if isinstance(v, torch.Tensor):
                                    if k in new_state_slot and new_state_slot[k].shape == v.shape:
                                        new_state_slot[k].copy_(v.to(new_state_slot[k].device))
                                    else:
                                        new_state_slot[k] = v.to(new_state_slot.get(k, v).device)
                                else:
                                    new_state_slot[k] = v
                            transferred += 1
                        except Exception:
                            skipped += 1
                    else:
                        skipped += 1
                if self.rank == 0 and transferred>0:
                    print(f"   ğŸ”„ Optimizer state migrated: {transferred} tensors (skipped {skipped})")
            except Exception as e:
                if self.rank == 0:
                    print(f"   âš ï¸ Optimizer state migration failed: {e}")
        if not os.path.exists(checkpoint_path):
            self.logger.error(f"Checkpoint file not found: {checkpoint_path}")
            return 0 # Return 0 to indicate training should start from epoch 0

        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            # å¯¬é¬†è¼‰å…¥ï¼šå…è¨±å¤šå‡ºçš„éµï¼ˆä¾‹å¦‚èˆŠç‰ˆ LAAF çš„ a_raw åƒæ•¸ï¼‰
            res_main = self.get_model(self.net).load_state_dict(checkpoint['net_state_dict'], strict=False)
            res_evm  = self.get_model(self.net_1).load_state_dict(checkpoint['net_1_state_dict'], strict=False)
            # è¨˜éŒ„ä¸ç›¸å®¹éµï¼Œä¾¿æ–¼è¨ºæ–·
            if res_main.unexpected_keys or res_main.missing_keys:
                self.logger.warning(f"Main net state_dict mismatches. unexpected={len(res_main.unexpected_keys)}, missing={len(res_main.missing_keys)}")
                # å¸¸è¦‹ï¼šactivation å±¤çš„ LAAF åƒæ•¸ a_raw ä¾†è‡ªèˆŠ checkpoint
                laaf_unexpected = [k for k in res_main.unexpected_keys if 'a_raw' in k]
                if laaf_unexpected:
                    self.logger.info(f"Ignored legacy LAAF keys in main net: {laaf_unexpected[:4]}{' ...' if len(laaf_unexpected)>4 else ''}")
            if res_evm.unexpected_keys or res_evm.missing_keys:
                self.logger.warning(f"EVM net state_dict mismatches. unexpected={len(res_evm.unexpected_keys)}, missing={len(res_evm.missing_keys)}")

            # å…ˆè®€å–ä¿å­˜çš„ wd
            saved_wd = checkpoint.get('current_weight_decay', 0.0)
            self.current_weight_decay = saved_wd

            # å˜—è©¦è¼‰å…¥èˆŠ optimizer stateï¼ˆè‹¥çµæ§‹ä¸ç¬¦æœƒå¾ŒçºŒé‡å»ºï¼‰
            opt_state = checkpoint.get('optimizer_state_dict', None)
            legacy_state = None
            if opt_state and optimizer is not None:
                try:
                    # å˜—è©¦ç›´æ¥è¼‰å…¥ (å¯èƒ½å¤±æ•—æˆ–çµæ§‹ä¸ç¬¦)
                    self._load_optimizer_state_dict_safe(optimizer, opt_state)
                    # ä¿ç•™åŸå§‹ state ç”¨æ–¼å¾ŒçºŒé·ç§»
                    legacy_state = {k:v for k,v in optimizer.state.items()}
                except Exception:
                    legacy_state = None

            # æ±ºå®šæ˜¯å¦éœ€è¦é‡å»º param groups
            if _needs_rebuild(optimizer):
                if self.rank == 0:
                    print("   âš ï¸ Detected legacy/invalid optimizer param_groups â†’ rebuilding AdamW")
                # ç²å– lrï¼ˆå¾ opt_state æˆ– fallbackï¼‰
                lr_guess = 1e-3
                try:
                    if optimizer and optimizer.param_groups:
                        lr_guess = optimizer.param_groups[0].get('lr', lr_guess)
                except Exception:
                    pass
                # é‡å»º AdamW (é€™æœƒè¦†å¯« self.opt)
                self.build_adamw_optimizer(lr_guess, saved_wd)
                if optimizer is not self.opt:
                    optimizer = self.opt
                # é·ç§»ç‹€æ…‹
                if legacy_state:
                    _migrate_state(legacy_state, optimizer)
            else:
                # è‹¥çµæ§‹æ­£å¸¸ï¼Œç¢ºä¿ current_weight_decay èˆ‡ group ä¸€è‡´
                try:
                    has_decay = False
                    for pg in optimizer.param_groups:
                        if pg.get('weight_decay',0.0)>0:
                            has_decay = True
                            if abs(pg['weight_decay']-saved_wd)>1e-12:
                                if self.rank==0:
                                    print(f"   âš ï¸ Mismatch wd(group={pg['weight_decay']}) vs saved({saved_wd}), syncing to saved")
                                pg['weight_decay']=saved_wd
                    if not has_decay and saved_wd>0:
                        if self.rank==0:
                            print("   âš ï¸ Saved checkpoint had weight_decay>0 but current groups have none; rebuilding")
                        lr_guess = optimizer.param_groups[0].get('lr',1e-3)
                        self.build_adamw_optimizer(lr_guess, saved_wd)
                except Exception:
                    pass

            start_epoch = checkpoint['epoch'] + 1
            self.global_step_offset = checkpoint.get('global_step_offset', 0)
            self.Re = checkpoint.get('Re', self.Re)
            self.alpha_evm = checkpoint.get('alpha_evm', self.alpha_evm)
            if self.rank == 0:
                print(f"   Restored weight decay: {self.current_weight_decay}")
            self.logger.info(f"âœ… Resumed training from checkpoint: {checkpoint_path} at epoch {start_epoch}")
            for state in optimizer.state.values():
                for k, v in state.items():
                    if isinstance(v, torch.Tensor):
                        state[k] = v.to(self.device)
            # Scheduler å¯èƒ½å…ˆå‰å°šæœªæ§‹å»ºï¼ˆéœ€è¨“ç·´å¾ªç’°æ³¨å…¥ï¼‰ï¼Œæ­¤è™•åƒ…ä¿ç•™ wd
            return start_epoch
        except Exception as e:
            self.logger.error(f"Failed to load checkpoint from {checkpoint_path}: {e}")
            return 0 # Start from scratch if loading fails
        # (legacy duplicate implementation removed)
            
    def init_vis_t(self):
        """å„ªåŒ–ç‰ˆæœ¬ï¼šé¿å…ä¸å¿…è¦çš„CPUè½‰æ›"""
        (_,_,_,e_raw) = self.neural_net_u(self.x_f, self.y_f)
        # ä½¿ç”¨é…ç½®æ¿€æ´»æ˜ å°„å¾—åˆ°éè² çš„ EVM ç²˜æ»¯ï¼ˆæœªåŠ ä¸Šé™ï¼‰
        nu_e = self._compute_nu_e(e_raw)
        cap_val = float(self.beta) / float(self.Re) if self.beta is not None else (self.vis_t0)
        cap = torch.full_like(nu_e, cap_val)
        self.vis_t_minus_gpu = torch.minimum(self.alpha_evm * nu_e.detach(), cap)

    def set_boundary_data(self, X=None, time=False):
        # æ¥å—å·²åˆ‡ç‰‡ä¸”åœ¨æ­£ç¢ºè£ç½®ä¸Šçš„å¼µé‡ï¼Œç›´æ¥è³¦å€¼
        if X is None:
            self.logger.warning("é‚Šç•Œæ•¸æ“šç‚ºNoneï¼Œè·³éè¨­ç½®")
            return
        
        if len(X) < 4:
            self.logger.error(f"é‚Šç•Œæ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼ŒæœŸæœ›è‡³å°‘4å€‹å…ƒç´ ï¼Œå¾—åˆ°{len(X)}å€‹")
            return
            
        self.x_b, self.y_b, self.u_b, self.v_b = X[:4]
        if time and len(X) > 4:
            self.t_b = X[4]
        total_points = (self.x_b.shape[0] if isinstance(self.x_b, torch.Tensor) else 0)
        
    def set_eq_training_data(self, X=None, time=False):
        # æ¥å—å·²åˆ‡ç‰‡ä¸”åœ¨æ­£ç¢ºè£ç½®ä¸Šçš„å¼µé‡ï¼Œç›´æ¥è³¦å€¼
        if X is None:
            self.logger.warning("è¨“ç·´æ•¸æ“šç‚ºNoneï¼Œè·³éè¨­ç½®")
            return
            
        if len(X) < 2:
            self.logger.error(f"è¨“ç·´æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼ŒæœŸæœ›è‡³å°‘2å€‹å…ƒç´ ï¼Œå¾—åˆ°{len(X)}å€‹")
            return
            
        self.x_f, self.y_f = X[:2]
        if time and len(X) > 2:
            self.t_f = X[2]
        # Ensure gradients for PDE points
        if isinstance(self.x_f, torch.Tensor):
            self.x_f.requires_grad_(True)
        if isinstance(self.y_f, torch.Tensor):
            self.y_f.requires_grad_(True)
        total_points = (self.x_f.shape[0] if isinstance(self.x_f, torch.Tensor) else 0)
        if self.rank == 0:
            print(f"GPU {self.rank}: Processing {total_points} equation points")
        if hasattr(self, 'config') and hasattr(self.config, 'physics') and hasattr(self.config.physics, 'beta'):
            self.beta = float(self.config.physics.beta)
        else:
            self.beta = 1.0
        self.init_vis_t()

        # === é è¨ˆç®— PDE è·é›¢æ¬Šé‡ w(d)ï¼ˆåƒ…åœ¨å•Ÿç”¨æ™‚ï¼Œä¸¦å›ºå®šæ–¼ç•¶å‰ç­‰å¼é»é›†ï¼‰ ===
        # å¥½è™•ï¼šé¿å…æ¯å€‹ epoch é‡è¤‡è¨ˆç®— exp/min/normalizeï¼Œé™ä½å‰å‘è€—æ™‚èˆ‡æŠ–å‹•
        try:
            enable_weight = True
            w_min = 0.2
            tau = 0.1
            if hasattr(self, 'config') and hasattr(self.config, 'training'):
                tr = self.config.training
                enable_weight = bool(getattr(tr, 'pde_distance_weighting', True))
                w_min = float(getattr(tr, 'pde_distance_w_min', 0.2))
                tau = float(getattr(tr, 'pde_distance_tau', 0.1))

            if enable_weight and isinstance(self.x_f, torch.Tensor) and isinstance(self.y_f, torch.Tensor):
                with torch.no_grad():
                    d_x = torch.minimum(self.x_f + 1.0, 1.0 - self.x_f)
                    d_y = torch.minimum(self.y_f + 1.0, 1.0 - self.y_f)
                    d = torch.minimum(d_x, d_y)
                    w = w_min + (1.0 - w_min) * torch.exp(-d / max(tau, 1e-6))
                    # å‡å€¼æ­¸ä¸€ï¼Œä¸¦å›ºå®šç‚ºå¸¸æ•¸å¼µé‡ï¼ˆé¿å…é€²å…¥è¨ˆç®—åœ–ï¼‰
                    w = (w / (w.mean() + 1e-12)).detach()
                self.w_f = w
            else:
                self.w_f = None
        except Exception:
            # ä¿å®ˆå›é€€
            self.w_f = None

    def set_optimizers(self, opt):
        self.opt = opt

    # ================= AdamW / Weight Decay æ”¯æ´ =================
    def _build_param_groups(self, weight_decay: float) -> list:
        """å»ºç«‹ AdamW åƒæ•¸åˆ†çµ„ï¼šå¯è¨“ç·´åƒæ•¸ä¸­ï¼Œç¶­åº¦>1ä¸”é bias æ–½åŠ  decayã€‚"""
        params_decay = []
        params_nodecay = []
        for model in [self.get_model(self.net), self.get_model(self.net_1)]:
            for name, p in model.named_parameters():
                if not p.requires_grad:
                    continue
                if p.dim() > 1 and not name.endswith('bias'):
                    params_decay.append(p)
                else:
                    params_nodecay.append(p)
        groups = []
        if params_decay:
            groups.append({'params': params_decay, 'weight_decay': weight_decay})
        if params_nodecay:
            groups.append({'params': params_nodecay, 'weight_decay': 0.0})
        return groups

    def print_optimizer_groups(self):
        """è¨ºæ–·è¼¸å‡ºç›®å‰ AdamW åƒæ•¸çµ„è³‡è¨Šã€‚"""
        if self.opt is None:
            if self.rank == 0:
                print("   (optimizer not initialized)")
            return
        if self.rank != 0:
            return
        try:
            total_params = 0
            print("--- Optimizer Param Groups (AdamW) ---")
            for i, g in enumerate(self.opt.param_groups):
                params = g.get('params', [])
                count = sum(p.numel() for p in params if isinstance(p, torch.Tensor))
                total_params += count
                wd = g.get('weight_decay', 0.0)
                sample_names = []
                # å–å‰3å€‹åç¨±
                name_map = self._param_name_map(self.get_model(self.net)) | self._param_name_map(self.get_model(self.net_1))
                for p in params[:3]:
                    n = name_map.get(id(p), 'unknown')
                    sample_names.append(n)
                print(f"Group {i}: params={count}, wd={wd}, sample={sample_names}")
            print(f"Total trainable params: {total_params}")
            print(f"Current weight_decay tracked: {getattr(self,'current_weight_decay',0.0)}")
            print("--------------------------------------")
        except Exception as e:
            if self.rank == 0:
                print(f"   âš ï¸ print_optimizer_groups error: {e}")

    def build_adamw_optimizer(self, lr: float, weight_decay: float):
        """å»ºç«‹æ–°çš„ AdamW ä¸¦æ›´æ–° self.optï¼ŒåŒæ™‚ä¿ç•™ scheduler é€£çºŒæ€§è³‡è¨Šã€‚"""
        from torch.optim import AdamW
        groups = self._build_param_groups(weight_decay)
        self.opt = AdamW(groups, lr=lr, betas=(0.9, 0.999))
        for pg in self.opt.param_groups:
            pg['initial_lr'] = lr
        self.current_weight_decay = weight_decay
        # é‡å»º scheduler ä»¥ç¶å®šæ–° optimizerï¼ˆè‹¥å·²æœ‰è¨˜éŒ„ï¼‰
        try:
            self._rebuild_scheduler()
        except Exception:
            pass
        if self.rank == 0:
            print(f"ğŸ”§ æ§‹å»º AdamW: lr={lr:.2e}, wd={weight_decay}, groups={len(self.opt.param_groups)}")
        return self.opt

    def rebuild_after_structure_change(self):
        """åœ¨ freeze/unfreeze æˆ– L-BFGS å¾Œé‡å»º AdamWï¼ˆä¿æŒ lr / wdï¼‰ã€‚"""
        if not hasattr(self, 'current_weight_decay'):
            self.current_weight_decay = 0.0
        lr = 1e-3
        if self.opt is not None and self.opt.param_groups:
            lr = self.opt.param_groups[0].get('lr', lr)
        self.build_adamw_optimizer(lr, self.current_weight_decay)

    def set_alpha_evm(self, alpha):
        self.alpha_evm = alpha

    def _check_gradients(self):
        """æª¢æŸ¥æ¢¯åº¦ç‹€æ…‹ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸"""
        total_norm = 0
        param_count = 0
        for p in list(self.net.parameters()) + list(self.net_1.parameters()):
            if p.grad is not None:
                total_norm += p.grad.data.norm(2).item() ** 2
                param_count += 1
        
        if param_count > 0:
            total_norm = total_norm ** (1. / 2)
            return total_norm
        return 0.0

    def check_tanh_saturation(self, epoch_id):
        """æª¢æ¸¬æ¿€æ´»å‡½æ•¸é£½å’Œæƒ…æ³ï¼ˆtanh æˆ– LAAF+tnahï¼‰ä½¿ç”¨å…¨åŸŸæ­¥æ•¸ä¸²æ¥æ‰€æœ‰stageã€‚

        å°æ–¼ LAAFï¼Œé£½å’Œæ¢ä»¶ä»¥ |a * pre| > 2 ä¼°ç®—ã€‚
        """
        if epoch_id % 1000 == 0 and self.rank == 0:  # é »ç‡æ§åˆ¶ä»æ²¿ç”¨å‘¼å«ç«¯ + 1000æ­¥ç¯€æµ
            # å…¨åŸŸæ­¥æ•¸ï¼ˆè·¨ stage å–®èª¿éå¢ï¼‰é¿å…TensorBoardè¦†å¯«
            global_step = getattr(self, 'global_step_offset', 0) + epoch_id
            saturation_info = []
            
            # æª¢æŸ¥ä¸»ç¶²çµ¡
            with torch.no_grad():
                test_input = torch.cat([self.x_f[:100], self.y_f[:100]], dim=1)
                layer_count = 0
                # ä½¿ç”¨Sequentialçµæ§‹é…å° Linear -> activation
                main_layers = getattr(self.get_model(self.net), 'layers', None)
                if isinstance(main_layers, torch.nn.Sequential):
                    idx = 0
                    keys = list(main_layers._modules.keys())
                    while idx < len(keys):
                        key = keys[idx]
                        mod = main_layers._modules[key]
                        if isinstance(mod, torch.nn.Linear):
                            pre = torch.matmul(test_input, mod.weight.T) + mod.bias
                            # å°‹æ‰¾ä¸‹ä¸€å€‹æ¿€æ´»
                            sat_ratio = 0.0
                            next_act = None
                            if idx + 1 < len(keys):
                                next_act = main_layers._modules[keys[idx + 1]]
                            if isinstance(next_act, torch.nn.Tanh):
                                sat_ratio = (pre.abs() > 2.0).float().mean().item()
                                test_input = torch.tanh(pre)
                            elif isinstance(next_act, LAAFScalar):
                                # é£½å’Œæ¢ä»¶ï¼š|a*pre| > 2
                                a = next_act.a
                                sat_ratio = ((a * pre).abs() > 2.0).float().mean().item()
                                test_input = next_act(pre)
                            else:
                                # æœªçŸ¥æ¿€æ´»ï¼Œé€€åŒ–ç‚ºtanhä¼°ç®—
                                sat_ratio = (pre.abs() > 2.0).float().mean().item()
                                test_input = torch.tanh(pre)
                            saturation_info.append((f"ä¸»ç¶²çµ¡_Layer{layer_count}", sat_ratio))
                            layer_count += 1
                            idx += 2
                        else:
                            idx += 1
                else:
                    # å¾Œå‚™æ–¹æ¡ˆï¼šèˆ‡èˆŠé‚è¼¯ä¸€è‡´
                    for name, module in self.get_model(self.net).named_modules():
                        if isinstance(module, torch.nn.Linear):
                            pre = torch.matmul(test_input, module.weight.T) + module.bias
                            sat_ratio = (pre.abs() > 2.0).float().mean().item()
                            saturation_info.append((f"ä¸»ç¶²çµ¡_Layer{layer_count}", sat_ratio))
                            test_input = torch.tanh(pre)
                            layer_count += 1
                
                # æª¢æŸ¥EVMç¶²çµ¡
                test_input_evm = torch.cat([self.x_f[:100], self.y_f[:100]], dim=1)
                layer_count = 0
                evm_layers = getattr(self.get_model(self.net_1), 'layers', None)
                if isinstance(evm_layers, torch.nn.Sequential):
                    idx = 0
                    keys = list(evm_layers._modules.keys())
                    while idx < len(keys):
                        key = keys[idx]
                        mod = evm_layers._modules[key]
                        if isinstance(mod, torch.nn.Linear):
                            pre = torch.matmul(test_input_evm, mod.weight.T) + mod.bias
                            next_act = None
                            if idx + 1 < len(keys):
                                next_act = evm_layers._modules[keys[idx + 1]]
                            if isinstance(next_act, torch.nn.Tanh):
                                sat_ratio = (pre.abs() > 2.0).float().mean().item()
                                test_input_evm = torch.tanh(pre)
                            elif isinstance(next_act, LAAFScalar):
                                a = next_act.a
                                sat_ratio = ((a * pre).abs() > 2.0).float().mean().item()
                                test_input_evm = next_act(pre)
                            else:
                                sat_ratio = (pre.abs() > 2.0).float().mean().item()
                                test_input_evm = torch.tanh(pre)
                            saturation_info.append((f"EVMç¶²çµ¡_Layer{layer_count}", sat_ratio))
                            layer_count += 1
                            idx += 2
                        else:
                            idx += 1
                else:
                    for name, module in self.get_model(self.net_1).named_modules():
                        if isinstance(module, torch.nn.Linear):
                            pre = torch.matmul(test_input_evm, module.weight.T) + module.bias
                            sat_ratio = (pre.abs() > 2.0).float().mean().item()
                            saturation_info.append((f"EVMç¶²çµ¡_Layer{layer_count}", sat_ratio))
                            test_input_evm = torch.tanh(pre)
                            layer_count += 1
            
            # è¼¸å‡ºè¨ºæ–·ä¿¡æ¯
            high_saturation_layers = [(name, ratio) for name, ratio in saturation_info if ratio > 0.3]
            if high_saturation_layers:
                self.logger.warning(f"âš ï¸  é«˜é£½å’Œå±¤ (>30%): {high_saturation_layers}")
            
            # è¨˜éŒ„åˆ°TensorBoardï¼ˆä½¿ç”¨global_stepé¿å…è¦†å¯«ï¼‰
            if self.tb_writer is not None:
                for name, ratio in saturation_info:
                    self.safe_tensorboard_log(f"NetworkHealth/Saturation_{name}", ratio, global_step)
            
            # æ¢¯åº¦åˆ†æ (å¢å¼·è¨ºæ–·)
            grad_norms = []
            avg_grad_norm = 0.0
            if hasattr(self, 'opt') and self.opt is not None:
                for param_group in self.opt.param_groups:
                    for param in param_group['params']:
                        if param.grad is not None:
                            grad_norms.append(param.grad.norm().item())
                if grad_norms:
                    avg_grad_norm = sum(grad_norms) / len(grad_norms)
                    max_grad_norm = max(grad_norms)
                    if self.tb_writer is not None:
                        self.safe_tensorboard_log('NetworkHealth/Avg_Grad_Norm', avg_grad_norm, global_step)
                        self.safe_tensorboard_log('NetworkHealth/Max_Grad_Norm', max_grad_norm, global_step)
                    if avg_grad_norm < 1e-6:
                        self.logger.warning(f"ğŸ”» æ¢¯åº¦ç•°å¸¸å°: {avg_grad_norm:.2e} (å¯èƒ½æ¢¯åº¦æ¶ˆå¤±)")
                    elif avg_grad_norm > 1e2:
                        self.logger.warning(f"ğŸ”º æ¢¯åº¦ç•°å¸¸å¤§: {avg_grad_norm:.2e} (å¯èƒ½æ¢¯åº¦çˆ†ç‚¸)")
            
            # è¼¸å‡ºé‡ç´šæª¢æŸ¥
            with torch.no_grad():
                sample_input = torch.cat([self.x_f[:50], self.y_f[:50]], dim=1)
                main_output = self.net(sample_input)
                evm_output = self.net_1(sample_input)
                velocity_max = main_output[:, :2].abs().max().item()
                evm_max = evm_output.abs().max().item()
                if self.tb_writer is not None:
                    self.safe_tensorboard_log('NetworkHealth/Velocity_Output_Max', velocity_max, global_step)
                    self.safe_tensorboard_log('NetworkHealth/EVM_Output_Max', evm_max, global_step)
                if velocity_max > 2.0:
                    self.logger.warning(f"ğŸŒŠ é€Ÿåº¦è¼¸å‡ºéå¤§: {velocity_max:.3f} (å»ºè­°<2.0)")
                if evm_max > 0.1:
                    self.logger.warning(f"ğŸ’¨ EVMè¼¸å‡ºéå¤§: {evm_max:.3f} (å»ºè­°<0.1)")
            
            # è¨ˆç®—å¹³å‡é£½å’Œç‡
            avg_saturation = sum(ratio for _, ratio in saturation_info) / len(saturation_info) if saturation_info else 0.0
            
            # æ•´é«”å¥åº·ç‹€æ…‹è©•ä¼°
            health_issues = []
            if hasattr(self, 'opt') and grad_norms:
                if avg_grad_norm < 1e-6:
                    health_issues.append("æ¢¯åº¦æ¶ˆå¤±")
                elif avg_grad_norm > 1e2:
                    health_issues.append("æ¢¯åº¦çˆ†ç‚¸")
            if 'velocity_max' in locals() and velocity_max > 2.0:
                health_issues.append("é€Ÿåº¦è¼¸å‡ºéå¤§")
            if 'evm_max' in locals() and evm_max > 0.1:
                health_issues.append("EVMè¼¸å‡ºéå¤§")
            if health_issues:
                self.logger.warning(f"ğŸ¥ ç¶²è·¯å¥åº·è­¦å‘Š: {'; '.join(health_issues)}")
            else:
                self.logger.info(f"âœ… ç¶²è·¯å¥åº·ç‹€æ…‹è‰¯å¥½ (é£½å’Œç‡: {avg_saturation*100:.1f}%)")
            if avg_saturation > 0.2:
                self.logger.warning(f"ğŸ”¥ å¹³å‡é£½å’Œç‡: {avg_saturation*100:.1f}% (å»ºè­°<20%)")

    def initialize_NN(self,
                      num_ins=3,
                      num_outs=3,
                      num_layers=10,
                      hidden_size=50,
                      is_evm: bool = False):
        """å»ºç«‹ä¸»ç¶²/å‰¯ç¶²ï¼Œæ ¹æ“šé…ç½®é¸æ“‡æ¿€æ´»å‡½æ•¸ï¼ˆæ”¯æ´ LAAFï¼‰å’Œç¥ç¶“å…ƒæ•¸é‡ã€‚"""
        activation_factory = torch.nn.Tanh
        hidden_sizes = None
        
        cfg = getattr(self, 'config', None)
        if cfg is not None and hasattr(cfg, 'network'):
            ncfg = cfg.network
            
            # ç²å–æ¯å±¤ç¥ç¶“å…ƒé…ç½®
            if is_evm:
                # EVMç¶²è·¯é…ç½®
                if hasattr(ncfg, 'hidden_sizes_1') and ncfg.hidden_sizes_1 is not None:
                    hidden_sizes = ncfg.hidden_sizes_1
                    if len(hidden_sizes) != num_layers:
                        self.logger.warning(f"EVM hidden_sizes_1é•·åº¦({len(hidden_sizes)})èˆ‡layers_1({num_layers})ä¸ç¬¦ï¼Œä½¿ç”¨hidden_size_1")
                        hidden_sizes = None
            else:
                # ä¸»ç¶²è·¯é…ç½®  
                if hasattr(ncfg, 'hidden_sizes') and ncfg.hidden_sizes is not None:
                    hidden_sizes = ncfg.hidden_sizes
                    if len(hidden_sizes) != num_layers:
                        self.logger.warning(f"ä¸»ç¶² hidden_sizesé•·åº¦({len(hidden_sizes)})èˆ‡layers({num_layers})ä¸ç¬¦ï¼Œä½¿ç”¨hidden_size")
                        hidden_sizes = None
            
            # é¸æ“‡ main æˆ– evm çš„ activation è¨­å®š
            act_name = (ncfg.activation_evm if is_evm else ncfg.activation_main).strip().lower()
            if act_name == 'laaf':
                init_scale = float(getattr(ncfg, 'laaf_init_scale', 1.0))
                max_scale = float(getattr(ncfg, 'laaf_max_scale', 20.0))
                # ä»¥åå‡½å¼æ–¹å¼æä¾› layer-wise åƒæ•¸
                def _factory():
                    return LAAFScalar(init_scale=init_scale, max_scale=max_scale)
                activation_factory = _factory
            else:
                activation_factory = torch.nn.Tanh
                
        return FCNet(num_ins=num_ins,
                     num_outs=num_outs,
                     num_layers=num_layers,
                     hidden_size=hidden_size,
                     hidden_sizes=hidden_sizes,
                     activation=activation_factory)

    def set_eq_training_func(self, train_data_func):
        self.train_data_func = train_data_func

    def neural_net_u(self, x, y):
        X = torch.cat((x, y), dim=1)
        
        # ç¢ºä¿è¼¸å…¥å¼µé‡åœ¨æ­£ç¢ºçš„è¨­å‚™ä¸Š
        X = X.to(self.device)
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¢ºä¿æ¢¯åº¦æ­£ç¢ºå‚³æ’­
        with torch.enable_grad():
            uvp = self.net(X)
            ee = self.net_1(X)
        
        u = uvp[:, 0]
        v = uvp[:, 1]
        p = uvp[:, 2:3]
        e = ee[:, 0:1]
        return u, v, p, e  # è¿”å›åŸå§‹æ®˜å·®é æ¸¬ e_raw

    def neural_net_equations(self, x, y):
        """å„ªåŒ–ç‰ˆæœ¬ï¼šæ¸›å°‘é‡è¤‡è¨ˆç®—å’Œæ‰¹é‡åŒ–æ¢¯åº¦è¨ˆç®—"""
        X = torch.cat((x, y), dim=1)
        
        # ç¢ºä¿è¼¸å…¥å¼µé‡åœ¨æ­£ç¢ºçš„è¨­å‚™ä¸Š
        X = X.to(self.device)
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¢ºä¿æ¢¯åº¦æ­£ç¢ºå‚³æ’­
        with torch.enable_grad():
            uvp = self.net(X)
            ee = self.net_1(X)

        u = uvp[:, 0:1]
        v = uvp[:, 1:2]
        p = uvp[:, 2:3]
        e_raw = ee[:, 0:1]
        self.evm = e_raw

        # å„ªåŒ–ï¼šæ‰¹é‡è¨ˆç®—æ‰€æœ‰ä¸€éšæ¢¯åº¦
        outputs = [u, v, p]
        grads = self.compute_gradients_batch(outputs, [x, y])
        
        u_x, u_y = grads[0]
        v_x, v_y = grads[1]
        p_x, p_y = grads[2]
        
        # å„ªåŒ–ï¼šæ‰¹é‡è¨ˆç®—äºŒéšæ¢¯åº¦
        second_order_outputs = [u_x, u_y, v_x, v_y]
        second_order_inputs = [x, y, x, y]
        second_grads = self.compute_second_gradients_batch(second_order_outputs, second_order_inputs)
        
        u_xx, u_yy, v_xx, v_yy = second_grads

        # è¨ˆç®—éè² çš„EVMç²˜æ»¯ï¼ˆå¸¶ä¸Šé™ï¼‰
        batch_size = x.shape[0]
        # åŸºæ–¼ä¸Šä¸€è¼ªçš„ vis_t_minusï¼Œèˆ‡ vis_t0 åŠ beta/Re å…±åŒè£åˆ‡
        self.vis_t = self._compute_vis_t_optimized(batch_size, e_raw)
            
        # æ›´æ–° vis_t_minus (ç§»åˆ°GPUä¸Šé¿å…CPU-GPUè½‰æ›)
        cap_val = float(self.beta) / float(self.Re) if self.beta is not None else (1.0 / float(self.Re))
        nu_e_now = self._compute_nu_e(e_raw)
        if not getattr(self, 'lock_vis_t_minus', False):
            self.vis_t_minus_gpu = torch.minimum(self.alpha_evm * nu_e_now.detach(), torch.full_like(nu_e_now, cap_val))

        # å®šç¾©åŸŸå·²ç¶“æ˜¯ [-1,1]Â²ï¼Œæ¢¯åº¦å³ç‚ºç‰©ç†æ¢¯åº¦ï¼Œç„¡éœ€é¡å¤–ç¸®æ”¾
        # ç›´æ¥ä½¿ç”¨è¨ˆç®—çš„æ¢¯åº¦
        u_x_phys = u_x
        u_y_phys = u_y
        v_x_phys = v_x
        v_y_phys = v_y
        p_x_phys = p_x
        p_y_phys = p_y
        
        u_xx_phys = u_xx
        u_yy_phys = u_yy
        v_xx_phys = v_xx
        v_yy_phys = v_yy

        # NS equations - ä½¿ç”¨ç‰©ç†åº§æ¨™çš„å°æ•¸
        vis_total = (1.0/self.Re + self.vis_t)
        
        eq1 = (u*u_x_phys + v*u_y_phys) + p_x_phys - vis_total*(u_xx_phys + u_yy_phys)
        eq2 = (u*v_x_phys + v*v_y_phys) + p_y_phys - vis_total*(v_xx_phys + v_yy_phys)
        eq3 = u_x_phys + v_y_phys

        # ä¿æŒç†µæ®˜å·®æ–¹ç¨‹ä½¿ç”¨åŸå§‹ e_rawï¼ˆå¸¶ç¬¦è™Ÿï¼‰
        residual = (eq1*(u-0.5)+eq2*(v-0.5))-e_raw
        return eq1, eq2, eq3, residual

    def _compute_nu_e(self, e_raw: torch.Tensor) -> torch.Tensor:
        """Compute nonnegative EVM contribution before scaling/capping."""
        return torch.abs(e_raw)

    def compute_gradients_batch(self, outputs: List[torch.Tensor], inputs: List[torch.Tensor]) -> List[List[torch.Tensor]]:
        """
        æ‰¹é‡è¨ˆç®—å¤šå€‹è¼¸å‡ºå°å¤šå€‹è¼¸å…¥çš„æ¢¯åº¦ï¼Œæ¸›å°‘autogradèª¿ç”¨æ¬¡æ•¸
        """
        batch_gradients = []
        
        for output in outputs:
            grad_outputs = [torch.ones_like(output, device=output.device)]
            grads = torch.autograd.grad(
                [output],
                inputs,
                grad_outputs=grad_outputs,
                create_graph=True,
                retain_graph=True,
                allow_unused=True,
            )
            # è™•ç†Noneæ¢¯åº¦
            processed_grads = [g if g is not None else torch.zeros_like(inputs[i]) for i, g in enumerate(grads)]
            batch_gradients.append(processed_grads)
            
        return batch_gradients
    
    def compute_second_gradients_batch(self, first_grads: List[torch.Tensor], inputs: List[torch.Tensor]) -> List[torch.Tensor]:
        """
        æ‰¹é‡è¨ˆç®—äºŒéšæ¢¯åº¦
        """
        second_grads = []
        
        for i, grad in enumerate(first_grads):
            input_tensor = inputs[i]
            grad_outputs = [torch.ones_like(grad, device=grad.device)]
            second_grad = torch.autograd.grad(
                [grad],
                [input_tensor],
                grad_outputs=grad_outputs,
                create_graph=True,
                retain_graph=True,
                allow_unused=True,
            )[0]
            
            if second_grad is None:
                second_grad = torch.zeros_like(input_tensor)
            second_grads.append(second_grad)
            
        return second_grads
    
    def _compute_vis_t_optimized(self, batch_size: int, e: torch.Tensor) -> torch.Tensor:
        """
        å„ªåŒ–çš„vis_tè¨ˆç®—ï¼Œé¿å…CPU-GPUè½‰æ›å’Œnumpyæ“ä½œ
        """
        if hasattr(self, 'vis_t_minus_gpu') and self.vis_t_minus_gpu is not None:
            # ç¢ºä¿å°ºå¯¸åŒ¹é…
            if self.vis_t_minus_gpu.shape[0] != batch_size:
                if self.vis_t_minus_gpu.shape[0] > batch_size:
                    vis_t_minus_batch = self.vis_t_minus_gpu[:batch_size]
                else:
                    # GPUä¸Šçš„é‡è¤‡æ“ä½œ
                    repeat_times = (batch_size + self.vis_t_minus_gpu.shape[0] - 1) // self.vis_t_minus_gpu.shape[0]
                    vis_t_minus_batch = self.vis_t_minus_gpu.repeat(repeat_times, 1)[:batch_size]
            else:
                vis_t_minus_batch = self.vis_t_minus_gpu
            
            # åœ¨GPUä¸Šè¨ˆç®—minimum
            vis_t0_tensor = torch.full_like(vis_t_minus_batch, self.vis_t0)
            beta_cap = torch.full_like(vis_t_minus_batch, (float(self.beta) / float(self.Re)) if self.beta is not None else self.vis_t0)
            vis_t = torch.minimum(torch.minimum(vis_t0_tensor, vis_t_minus_batch), beta_cap)
        else:
            # é¦–æ¬¡é‹è¡Œæˆ–æ²’æœ‰å‰ä¸€æ­¥æ•¸æ“š
            vis_t = torch.full((batch_size, 1), self.vis_t0, device=self.device, dtype=torch.float32)
            
        return vis_t

    def autograd(self, y: torch.Tensor, x: List[torch.Tensor]) -> List[torch.Tensor]:
        """
        è¨ˆç®—æ¢¯åº¦çš„å‡½æ•¸ (ä¿ç•™åŸå‡½æ•¸ä»¥å…¼å®¹æ€§)
        """
        grad_outputs: List[torch.Tensor] = [torch.ones_like(y, device=y.device)]
        grad = torch.autograd.grad(
            [y],
            x,
            grad_outputs=grad_outputs,
            create_graph=True,
            retain_graph=True,
            allow_unused=True,
        )

        if grad is None:
            grad = [torch.zeros_like(xx) for xx in x]
        assert grad is not None
        grad = [g if g is not None else torch.zeros_like(x[i]) for i, g in enumerate(grad)]
        return grad

    def predict(self, net_params, X):
        x, y = X
        return self.neural_net_u(x, y)

    def shuffle(self, tensor):
        tensor_to_numpy = tensor.detach().cpu()
        shuffle_numpy = np.random.shuffle(tensor_to_numpy)
        return torch.tensor(tensor_to_numpy, requires_grad=True).float()

    def fwd_computing_loss_2d(self, loss_mode='MSE'):
        # boundary data
        (self.u_pred_b, self.v_pred_b, _, _) = self.neural_net_u(self.x_b, self.y_b)

        # BC loss - è™•ç†ç©ºé‚Šç•Œæ•¸æ“šçš„æƒ…æ³
        if loss_mode == 'MSE':
            if self.x_b.shape[0] > 0:  # æª¢æŸ¥æ˜¯å¦æœ‰é‚Šç•Œæ•¸æ“š
                # ç¢ºä¿å¼µé‡å½¢ç‹€åŒ¹é…
                u_b_flat = self.u_b.view(-1)
                v_b_flat = self.v_b.view(-1)
                u_pred_b_flat = self.u_pred_b.view(-1)
                v_pred_b_flat = self.v_pred_b.view(-1)
                
                # æª¢æŸ¥å¼µé‡å¤§å°æ˜¯å¦åŒ¹é…
                if u_b_flat.shape[0] != u_pred_b_flat.shape[0]:
                    print(f"ERROR: Boundary tensor size mismatch: {u_b_flat.shape} vs {u_pred_b_flat.shape}")
                    # ä½¿ç”¨è¼ƒå°çš„å°ºå¯¸
                    min_size = min(u_b_flat.shape[0], u_pred_b_flat.shape[0])
                    u_b_flat = u_b_flat[:min_size]
                    v_b_flat = v_b_flat[:min_size]
                    u_pred_b_flat = u_pred_b_flat[:min_size]
                    v_pred_b_flat = v_pred_b_flat[:min_size]
                
                self.loss_b = torch.mean(torch.square(u_b_flat - u_pred_b_flat)) + \
                              torch.mean(torch.square(v_b_flat - v_pred_b_flat))
            else:
                # æ²’æœ‰é‚Šç•Œæ•¸æ“šæ™‚è¨­ç½®æå¤±ç‚º0ï¼Œä½†ä¿æŒåœ¨è¨ˆç®—åœ–ä¸­
                # ç¢ºä¿å…©å€‹ç¶²è·¯éƒ½åƒèˆ‡è¨ˆç®—åœ–
                # ç²å–æ¨¡å‹ï¼ˆè™•ç†DDPåŒ…è£ï¼‰
                net_model = self.get_model(self.net)
                net1_model = self.get_model(self.net_1)
                
                # ç²å–ç¬¬ä¸€å€‹ç·šæ€§å±¤
                first_layer = None
                first_layer_1 = None
                for layer in net_model.layers:
                    if isinstance(layer, torch.nn.Linear):
                        first_layer = layer
                        break
                for layer in net1_model.layers:
                    if isinstance(layer, torch.nn.Linear):
                        first_layer_1 = layer
                        break
                
                if first_layer is not None and first_layer_1 is not None:
                    dummy_loss_net = torch.sum(first_layer.weight * 0.0)
                    dummy_loss_net1 = torch.sum(first_layer_1.weight * 0.0)
                    self.loss_b = dummy_loss_net + dummy_loss_net1
                else:
                    self.loss_b = torch.tensor(0.0, device=self.device)

        # equation
        assert self.x_f is not None and self.y_f is not None

        (self.eq1_pred, self.eq2_pred, self.eq3_pred, self.eq4_pred) = self.neural_net_equations(self.x_f, self.y_f)
    
        if loss_mode == 'MSE':
            # ä½¿ç”¨é è¨ˆç®—çš„è·é›¢æ¬Šé‡ï¼ˆè‹¥æœ‰ï¼‰ï¼›å¦å‰‡ä½¿ç”¨å¸¸æ•¸1.0
            w = getattr(self, 'w_f', None)
            if w is None:
                w = 1.0

            eq1_sq = torch.square(self.eq1_pred.view(-1))
            eq2_sq = torch.square(self.eq2_pred.view(-1))
            eq3_sq = torch.square(self.eq3_pred.view(-1))
            eq4_sq = torch.square(self.eq4_pred.view(-1))

            if isinstance(w, torch.Tensor):
                w_flat = w.view(-1)
                self.loss_eq1 = torch.mean(w_flat * eq1_sq)
                self.loss_eq2 = torch.mean(w_flat * eq2_sq)
                self.loss_eq3 = torch.mean(w_flat * eq3_sq)
                self.loss_eq4 = torch.mean(w_flat * eq4_sq)
            else:
                self.loss_eq1 = torch.mean(eq1_sq)
                self.loss_eq2 = torch.mean(eq2_sq)
                self.loss_eq3 = torch.mean(eq3_sq)
                self.loss_eq4 = torch.mean(eq4_sq)

            self.loss_e = self.loss_eq1 + self.loss_eq2 + self.loss_eq3 + 0.1 * self.loss_eq4

        # supervision loss
        if self.x_sup is not None and self.x_sup.shape[0] > 0:
            # è®¡ç®—ç›‘ç£ç‚¹çš„é¢„æµ‹å€¼
            (u_pred_sup, v_pred_sup, p_pred_sup, _) = self.neural_net_u(self.x_sup, self.y_sup)
            
            # è®¡ç®—ç›‘ç£æŸå¤±
            if loss_mode == 'MSE':
                u_sup_flat = self.u_sup.view(-1)
                v_sup_flat = self.v_sup.view(-1)
                p_sup_flat = self.p_sup.view(-1)
                u_pred_sup_flat = u_pred_sup.view(-1)
                v_pred_sup_flat = v_pred_sup.view(-1)
                p_pred_sup_flat = p_pred_sup.view(-1)
                
                self.loss_s = torch.mean(torch.square(u_pred_sup_flat - u_sup_flat)) + \
                              torch.mean(torch.square(v_pred_sup_flat - v_sup_flat)) + \
                              torch.mean(torch.square(p_pred_sup_flat - p_sup_flat))
        else:
            # æ²¡æœ‰ç›‘ç£æ•°æ®æ—¶ï¼Œè®¾ç½®æŸå¤±ä¸º0ä½†ä¿æŒåœ¨è®¡ç®—å›¾ä¸­
            if hasattr(self.net, 'module'):
                dummy_loss_net = torch.sum(self.net.module.layers[0].weight * 0.0)
                dummy_loss_net1 = torch.sum(self.net_1.module.layers[0].weight * 0.0)
            else:
                dummy_loss_net = torch.sum(self.net.layers[0].weight * 0.0)
                dummy_loss_net1 = torch.sum(self.net_1.layers[0].weight * 0.0)
            self.loss_s = dummy_loss_net + dummy_loss_net1

        # è·¨GPUèšåˆæå¤±ä»¥ç²å¾—å…¨å±€æå¤±å€¼ï¼ˆåƒ…ç”¨æ–¼æ—¥èªŒï¼šä½¿ç”¨ reduce åŒ¯ç¸½åˆ° rank 0ï¼‰
        if self.world_size > 1:
            # ç¢ºä¿lossè®Šæ•¸æ˜¯tensoré¡å‹
            loss_b_tensor = self.loss_b if isinstance(self.loss_b, torch.Tensor) else torch.tensor(self.loss_b, device=self.device)
            loss_e_tensor = self.loss_e if isinstance(self.loss_e, torch.Tensor) else torch.tensor(self.loss_e, device=self.device)
            loss_s_tensor = self.loss_s if isinstance(self.loss_s, torch.Tensor) else torch.tensor(self.loss_s, device=self.device)
            
            loss_vec = torch.stack([
                loss_b_tensor.detach(),
                loss_e_tensor.detach(),
                loss_s_tensor.detach()
            ])
            dist.reduce(loss_vec, dst=0, op=dist.ReduceOp.SUM)
            if self.rank == 0:
                loss_vec = loss_vec / self.world_size
                # ç”¨æ–¼æ—¥èªŒé¡¯ç¤ºçš„å¹³å‡æå¤±ï¼ˆrank 0ï¼‰
                self.loss_b_avg = loss_vec[0]
                self.loss_e_avg = loss_vec[1]
                self.loss_s_avg = loss_vec[2]
            else:
                # érank 0ä¸éœ€è¦å…¨åŸŸå¹³å‡ï¼Œä¿ç•™æœ¬åœ°å€¼ä¾›å¿…è¦æ™‚ä½¿ç”¨
                self.loss_b_avg = self.loss_b
                self.loss_e_avg = self.loss_e
                self.loss_s_avg = self.loss_s
        else:
            self.loss_b_avg = self.loss_b
            self.loss_e_avg = self.loss_e
            self.loss_s_avg = self.loss_s

        # è¨ˆç®—ç¸½æå¤±ï¼ˆä¿æŒæ¢¯åº¦è¿½è¸ªï¼‰ï¼ŒåŒ…å«ç›‘ç£æŸå¤±
        self.loss = self.alpha_b * self.loss_b + self.alpha_e * self.loss_e + self.alpha_s * self.loss_s
        
        # åˆ†ä½ˆå¼æ¨¡å¼ä¸‹çš„ dummy L2ï¼šç•¶ç„¡å¯¦éš› weight decay æ™‚æ‰å•Ÿç”¨ï¼Œé¿å…èˆ‡ AdamW é‡è¤‡
        if self.world_size > 1:
            use_dummy = True
            if hasattr(self, 'current_weight_decay') and getattr(self, 'current_weight_decay', 0.0) > 0:
                use_dummy = False
            else:
                if self.opt is not None:
                    for pg in self.opt.param_groups:
                        if pg.get('weight_decay', 0.0) > 0:
                            use_dummy = False
                            break
            if use_dummy:
                regularization_weight = 1e-8
                if hasattr(self.net, 'module'):
                    params_main = self.net.module.parameters()
                    params_evm = self.net_1.module.parameters()
                else:
                    params_main = self.net.parameters()
                    params_evm = self.net_1.parameters()
                net_reg = sum(p.pow(2).sum() for p in params_main)
                net1_reg = sum(p.pow(2).sum() for p in params_evm)
                self.loss = self.loss + regularization_weight * (net_reg + net1_reg)

        # LAAF æ­£å‰‡åŒ–ï¼ˆå¯é¸ï¼‰
        try:
            ncfg = getattr(self.config, 'network', None)
            laaf_lambda = float(getattr(ncfg, 'laaf_reg_lambda', 0.0)) if ncfg is not None else 0.0
        except Exception:
            laaf_lambda = 0.0
        if laaf_lambda > 0.0:
            try:
                reg_main = compute_laaf_regularization(self.get_model(self.net), target=1.0)
                reg_evm = compute_laaf_regularization(self.get_model(self.net_1), target=1.0)
                self.loss = self.loss + laaf_lambda * (reg_main + reg_evm)
            except Exception:
                pass


        # å‰µå»ºç”¨æ–¼backwardçš„lossï¼ˆä¿æŒæ¢¯åº¦ï¼‰
        loss_for_backward = self.loss
        
        # å‰µå»ºç”¨æ–¼æ—¥èªŒè¨˜éŒ„çš„detachedæ•¸å€¼
        if hasattr(self, 'loss_e_avg'):
            loss_e_log = self.loss_e_avg.detach().item() if isinstance(self.loss_e_avg, torch.Tensor) else float(self.loss_e_avg)
        else:
            loss_e_log = self.loss_e.detach().item() if isinstance(self.loss_e, torch.Tensor) else float(self.loss_e)
            
        if hasattr(self, 'loss_b_avg'):
            loss_b_log = self.loss_b_avg.detach().item() if isinstance(self.loss_b_avg, torch.Tensor) else float(self.loss_b_avg)
        else:
            loss_b_log = self.loss_b.detach().item() if isinstance(self.loss_b, torch.Tensor) else float(self.loss_b)
            
        if hasattr(self, 'loss_s_avg'):
            loss_s_log = self.loss_s_avg.detach().item() if isinstance(self.loss_s_avg, torch.Tensor) else float(self.loss_s_avg)
        else:
            loss_s_log = self.loss_s.detach().item() if isinstance(self.loss_s, torch.Tensor) else float(self.loss_s)

        return loss_for_backward, [loss_e_log, loss_b_log, loss_s_log, self.loss_eq1.detach().item(), self.loss_eq2.detach().item(), self.loss_eq3.detach().item(), self.loss_eq4.detach().item()]

    def train(self,
              num_epoch=1,
              lr=1e-4,
              optimizer=None,
              scheduler=None,
              batchsize=None,
              profiler=None,
              start_epoch=0):
        if self.opt is not None:
            # å°æ–¼SGDR (SequentialLR)ï¼Œéœ€è¦ç‰¹æ®Šè™•ç†ä»¥ç¢ºä¿æ–°éšæ®µçš„å­¸ç¿’ç‡æ­£ç¢ºè¨­ç½®
            if scheduler is not None and hasattr(scheduler, '_schedulers'):
                # SequentialLRæƒ…æ³ï¼šéœ€è¦æ›´æ–°åŸºç¤å­¸ç¿’ç‡ä½†ä¿æŒschedulerç‹€æ…‹
                current_lr = self.opt.param_groups[0]['lr']
                
                # æ›´æ–°åŸºç¤å­¸ç¿’ç‡å’Œinitial_lrï¼Œç¢ºä¿schedulerå¾æ­£ç¢ºçš„åŸºç¤é–‹å§‹
                for param_group in self.opt.param_groups:
                    param_group['initial_lr'] = lr
                
                # é‡ç½®schedulerç‹€æ…‹ä»¥ä½¿ç”¨æ–°çš„åŸºç¤å­¸ç¿’ç‡
                scheduler.last_epoch = -1
                
                if self.rank == 0:
                    print(f"ğŸ”§ æª¢æ¸¬åˆ°SequentialLR scheduler (SGDR)ï¼Œæ›´æ–°åŸºç¤lr: {current_lr:.6f} -> {lr:.6f}")
                    print(f"   é‡ç½®schedulerä»¥å¾æ–°åŸºç¤å­¸ç¿’ç‡é–‹å§‹")
            else:
                # ç„¡scheduleræˆ–éSequentialLRï¼šæ­£å¸¸è¨­ç½®å­¸ç¿’ç‡
                self.opt.param_groups[0]['lr'] = lr
        return self.solve_Adam(self.fwd_computing_loss_2d, num_epoch, batchsize, scheduler, profiler, start_epoch)

    def _stage_group_index(self) -> int:
        """å°‡ Stage 1-6 åˆ†ç‚ºä¸‰æ®µï¼š0:(1-2), 1:(3-4), 2:(5-6)"""
        try:
            name = str(self.current_stage)
            if 'Stage' in name:
                idx = int(name.split()[-1])
            else:
                idx = 1
        except Exception:
            idx = 1
        if idx <= 2:
            return 0
        elif idx <= 4:
            return 1
        return 2

    def _compute_ema(self, seq, gamma: float) -> float:
        """å°åºåˆ—åšEMAå¹³æ»‘ï¼ˆè¿”å›æœ€å¾ŒEMAï¼‰"""
        ema = None
        for v in seq:
            if ema is None:
                ema = float(v)
            else:
                ema = gamma * ema + (1.0 - gamma) * float(v)
        return float(ema) if ema is not None else 0.0

    def _check_distributed_lbfgs_trigger(self) -> bool:
        """åˆ†ä½ˆå¼L-BFGSè§¸ç™¼æª¢æ¸¬ï¼ˆæ”¹ç‚ºEMAç›¸å°æ”¹å–„ + æ¢¯åº¦/ç‰©ç†æ¢ä»¶ + å†·å»ï¼‰"""
        trigger_lbfgs = False

        # é…ç½®èˆ‡åˆ†ä½ˆå¼é–‹é—œ
        cfg = getattr(self, 'config', None)
        lbfgs_cfg = getattr(cfg.training, 'lbfgs', None) if cfg and hasattr(cfg, 'training') else None
        if lbfgs_cfg and not lbfgs_cfg.enabled_in_distributed and self.world_size > 1:
            return False

        # éšæ®µæª¢æŸ¥ï¼šåªåœ¨Stage 3+æ‰å…è¨±L-BFGSè§¸ç™¼
        group_idx = self._stage_group_index()
        enable_from_stage = getattr(lbfgs_cfg, 'enable_from_stage', 3) if lbfgs_cfg else 3
        current_stage_num = 1
        try:
            name = str(self.current_stage)
            if 'Stage' in name:
                current_stage_num = int(name.split()[-1])
        except Exception:
            current_stage_num = 1
        
        if current_stage_num < enable_from_stage:
            return False

         # å†·å»æª¢æŸ¥ï¼ˆä½¿ç”¨ç›¸å°æ­¥æ•¸è§£æ±ºéšæ®µåˆ‡æ›å•é¡Œï¼‰
        cooldown = getattr(lbfgs_cfg, 'cooldown_steps', 5000) if lbfgs_cfg else 5000
        
        # ç²å–ç•¶å‰éšæ®µèµ·å§‹æ­¥æ•¸ï¼Œç¢ºä¿ç›¸å°æ­¥æ•¸è¨ˆç®—æ­£ç¢º
        stage_start_step = getattr(self, 'stage_start_step', 0)
        current_relative_step = self.stage_step - stage_start_step
        last_strategy_relative_step = self.last_strategy_step - stage_start_step
        
        # ä½¿ç”¨ç›¸å°æ­¥æ•¸æª¢æŸ¥å†·å»
        if (current_relative_step - last_strategy_relative_step) < cooldown:
            # Debug: å¶çˆ¾è¼¸å‡ºå†·å»ç‹€æ…‹ï¼ˆæ¯5000æ­¥ä¸€æ¬¡ï¼‰
            if self.rank == 0 and self.stage_step % 5000 == 0:
                print(f"[L-BFGSå†·å»] ç•¶å‰ç›¸å°æ­¥æ•¸:{current_relative_step}, ä¸Šæ¬¡è§¸ç™¼ç›¸å°æ­¥æ•¸:{last_strategy_relative_step}, å†·å»éœ€æ±‚:{cooldown}")
            return False

        # éœ€è¦è¶³å¤ çš„æ»‘çª—
        group_idx = self._stage_group_index()
        windows = getattr(lbfgs_cfg, 'trigger_window_per_stage', [5000, 7500, 10000]) if lbfgs_cfg else [5000, 7500, 10000]
        min_improves = getattr(lbfgs_cfg, 'min_improve_pct_per_stage', [0.02, 0.01, 0.005]) if lbfgs_cfg else [0.02, 0.01, 0.005]
        W = int(windows[min(group_idx, len(windows)-1)])
        min_r = float(min_improves[min(group_idx, len(min_improves)-1)])
        gamma = float(getattr(lbfgs_cfg, 'ema_gamma', 0.95)) if lbfgs_cfg else 0.95

        if len(self.stage_loss_deque) < max(W, 50):
            return False

        if self.rank == 0:
            losses = list(self.stage_loss_deque)
            L_t = float(losses[-1])
            L_w = float(losses[-W])
            denom = max(self._compute_ema(losses[-W:], gamma), 1e-12)
            r = (L_w - L_t) / denom

            # æ¢¯åº¦æ¢ä»¶ï¼ˆç°¡åŒ–ï¼‰
            use_simple_grad_check = getattr(lbfgs_cfg, 'use_simple_grad_check', True) if lbfgs_cfg else True
            
            if use_simple_grad_check:
                # ç°¡åŒ–çš„æ¢¯åº¦æª¢æŸ¥ï¼šåªéœ€è¦æ»¿è¶³çµ•å°å€¼æˆ–ç›¸å°æ”¹å–„æ¢ä»¶
                grad_med = float(getattr(self, 'grad_median', 1e9))
                g_base = float(getattr(self, 'grad_baseline', grad_med))
                rel_ok = grad_med < (getattr(lbfgs_cfg, 'grad_relative_factor', 0.02) * g_base) if lbfgs_cfg else False  # æ”¾å¯¬åˆ°2%
                abs_ok = grad_med < (getattr(lbfgs_cfg, 'grad_median_abs_thresh', 2e-3) if lbfgs_cfg else 2e-3)  # æ”¾å¯¬åˆ°2e-3
                grad_ok = abs_ok or rel_ok
            else:
                # åŸå§‹è¤‡é›œæ¢¯åº¦æª¢æŸ¥
                grad_med = float(getattr(self, 'grad_median', 1e9))
                grad_iqr = float(getattr(self, 'grad_iqr', 0.0))
                grad_iqr_ratio = grad_iqr / (grad_med + 1e-12)
                g_base = float(getattr(self, 'grad_baseline', grad_med))
                rel_ok = grad_med < (getattr(lbfgs_cfg, 'grad_relative_factor', 0.01) * g_base) if lbfgs_cfg else False
                abs_ok = grad_med < (getattr(lbfgs_cfg, 'grad_median_abs_thresh', 1e-3) if lbfgs_cfg else 1e-3)
                cos_ema = float(getattr(self, 'grad_cos_ema', 0.0))
                cos_ok = cos_ema > (getattr(lbfgs_cfg, 'grad_cos_ema_thresh', 0.9) if lbfgs_cfg else 0.9)
                grad_ok = (abs_ok or rel_ok) and (grad_iqr_ratio < 5.0 or cos_ok)

            # ç‰©ç†æ¢ä»¶ï¼ˆæ”¾å¯¬ï¼‰
            alpha_threshold = getattr(lbfgs_cfg, 'alpha_evm_threshold', 0.02) if lbfgs_cfg else 0.02  # æ”¾å¯¬åˆ°0.02
            alpha_ok = self.alpha_evm <= alpha_threshold
            cap_ratio_p95 = float(getattr(self, 'vis_cap_p95', 0.0))  # ç”±è¨“ç·´å¾ªç’°ç¶­è­·
            cap_threshold = getattr(lbfgs_cfg, 'cap_ratio_threshold', 0.7) if lbfgs_cfg else 0.7  # æ”¾å¯¬åˆ°0.7
            phys_ok = cap_ratio_p95 < cap_threshold

            trigger_lbfgs = (r <= min_r) and grad_ok and alpha_ok and phys_ok

        # å»£æ’­
        if self.world_size > 1:
            try:
                data = [trigger_lbfgs]
                dist.broadcast_object_list(data, src=0)
                trigger_lbfgs = data[0]
            except Exception as e:
                if self.rank == 0:
                    print(f"ğŸš¨ L-BFGSè§¸ç™¼å»£æ’­å¤±æ•—: {e}")
                trigger_lbfgs = False

        return trigger_lbfgs

    def _log_tip_once(self, key: str, msg: str):
        """åœ¨rank0è¼¸å‡ºä¸€æ¬¡æç¤ºï¼Œæ¯1è¬æ­¥åŒé¡ä¸é‡è¤‡"""
        try:
            if self.rank != 0:
                return
            if not (hasattr(self, 'config') and hasattr(self.config, 'training') and getattr(self.config.training, 'log_tips', True)):
                return
            now = int(getattr(self, 'stage_step', 0))
            last = int(self._tips_last_step.get(key, -10**9))
            if now - last >= 10000:
                print("--- Tips ---\n" + msg)
                self._tips_last_step[key] = now
        except Exception:
            pass

    def _calculate_parameter_checksum(self, net_state, net1_state):
        """è¨ˆç®—åƒæ•¸æ ¡é©—ç¢¼"""
        checksum = 0.0
        for state_dict in [net_state, net1_state]:
            for param in state_dict.values():
                checksum += torch.sum(param).item()
        return checksum

    def _broadcast_model_parameters_with_verification(self):
        """åƒæ•¸å»£æ’­ä¸¦é©—è­‰ä¸€è‡´æ€§"""
        if self.world_size <= 1:
            return True
            
        try:
            if self.rank == 0:
                # æº–å‚™åƒæ•¸æ•¸æ“šä¸¦è¨ˆç®—æ ¡é©—ç¢¼
                net_state = {k: v.cpu() for k, v in self.get_model(self.net).state_dict().items()}
                net1_state = {k: v.cpu() for k, v in self.get_model(self.net_1).state_dict().items()}
                
                # è¨ˆç®—åƒæ•¸æ ¡é©—ç¢¼
                checksum = self._calculate_parameter_checksum(net_state, net1_state)
                payload = [net_state, net1_state, checksum]
            else:
                payload = [None, None, None]
            
            # å»£æ’­åƒæ•¸
            dist.broadcast_object_list(payload, src=0)
            
            # émaster rankè¼‰å…¥åƒæ•¸ä¸¦é©—è­‰
            if self.rank != 0:
                self.get_model(self.net).load_state_dict(payload[0], strict=True)
                self.get_model(self.net_1).load_state_dict(payload[1], strict=True)
                
                # é©—è­‰åƒæ•¸æ ¡é©—ç¢¼
                local_checksum = self._calculate_parameter_checksum(payload[0], payload[1])
                if abs(local_checksum - payload[2]) > 1e-10:
                    raise RuntimeError(f"Rank {self.rank}: åƒæ•¸æ ¡é©—å¤±æ•— (local={local_checksum:.6e}, expected={payload[2]:.6e})")
            
            # GPUåŒæ­¥
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            
            return True
            
        except Exception as e:
            if self.rank == 0:
                print(f"ğŸš¨ åƒæ•¸åŒæ­¥å¤±æ•—: {e}")
            return False

    def train_with_lbfgs_segment(self, max_outer_steps=None, lbfgs_params=None, log_interval=200, timeout_seconds=None):
        """å¢å¼·ç‰ˆåˆ†ä½ˆå¼L-BFGSè¨“ç·´æ®µ"""
        import copy
        
        # å¾é…ç½®ä¸­ç²å–åƒæ•¸
        lbfgs_config = getattr(self, 'config', None)
        if lbfgs_config and hasattr(lbfgs_config.training, 'lbfgs'):
            config_lbfgs = lbfgs_config.training.lbfgs
            if max_outer_steps is None:
                max_outer_steps = config_lbfgs.max_outer_steps
            if timeout_seconds is None:
                timeout_seconds = config_lbfgs.timeout_seconds
            if lbfgs_params is None:
                lbfgs_params = {
                    'max_iter': config_lbfgs.max_iter,
                    'history_size': config_lbfgs.history_size,
                    'tolerance_grad': config_lbfgs.tolerance_grad,
                    'tolerance_change': config_lbfgs.tolerance_change,
                    'line_search_fn': config_lbfgs.line_search_fn
                }
        
        # ä½¿ç”¨é»˜èªå€¼å¦‚æœæ²’æœ‰é…ç½®
        if max_outer_steps is None:
            max_outer_steps = 2000
        if timeout_seconds is None:
            timeout_seconds = 600
        if lbfgs_params is None:
            lbfgs_params = {
                'max_iter': 50,
                'history_size': 20,
                'tolerance_grad': 1e-8,
                'tolerance_change': 1e-9,
                'line_search_fn': 'strong_wolfe'
            }
        
        mode = "åˆ†ä½ˆå¼" if self.world_size > 1 else "å–®GPU"
        if self.rank == 0:
            print(f"=== é€²å…¥ {mode} L-BFGS æ®µ ===")
        
        # ä¿å­˜ç•¶å‰Adamç‹€æ…‹
        adam_state_backup = None
        if self.opt is not None:
            try:
                adam_state_backup = copy.deepcopy(self.opt.state_dict())
            except:
                pass
        
        success = False
        best_loss = float('inf')
        
        try:
            # æ®µå…§ç­–ç•¥ï¼šå¯é¸å‡çµEVMã€é–å®švis_t_minus
            if lbfgs_config and hasattr(lbfgs_config.training, 'lbfgs') and lbfgs_config.training.lbfgs.freeze_evm_during_lbfgs:
                self.freeze_evm_net(self.stage_step)
            self.lock_vis_t_minus = True

            if self.opt is not None:
                self.opt.zero_grad(set_to_none=True)
            params = list(self.get_model(self.net).parameters()) + list(self.get_model(self.net_1).parameters())
            lbfgs = torch.optim.LBFGS(params,
                                      max_iter=lbfgs_params.get('max_iter', 50),
                                      history_size=lbfgs_params.get('history_size', 20),
                                      tolerance_grad=lbfgs_params.get('tolerance_grad', 1e-8),
                                      tolerance_change=lbfgs_params.get('tolerance_change', 1e-9),
                                      line_search_fn=lbfgs_params.get('line_search_fn', 'strong_wolfe'))
            
            stagnation = 0
            start_time = time.time()
            patience = int(lbfgs_config.training.lbfgs.early_stop_patience) if lbfgs_config and hasattr(lbfgs_config.training, 'lbfgs') else 8
            min_delta = float(lbfgs_config.training.lbfgs.early_stop_min_delta) if lbfgs_config and hasattr(lbfgs_config.training, 'lbfgs') else 1e-4
            
            def closure():
                lbfgs.zero_grad(set_to_none=True)
                loss, _ = self.fwd_computing_loss_2d()
                if isinstance(loss, torch.Tensor):
                    loss.backward()
                else:
                    # å¦‚æœæ˜¯æ¨™é‡ï¼Œè½‰æ›ç‚ºtensor
                    loss = torch.tensor(loss, requires_grad=True, device=self.device)
                    loss.backward()
                return loss
            
            stop_reason = "done"
            if self.world_size > 1:
                # åˆ†ä½ˆå¼æ¨¡å¼ï¼šåƒ…rank 0åŸ·è¡ŒL-BFGS
                if self.rank == 0:
                    for step in range(max_outer_steps):
                        try:
                            loss_prev = best_loss
                            loss_val = lbfgs.step(closure).item()
                            if step % log_interval == 0:
                                print(f"[åˆ†ä½ˆå¼ L-BFGS] step={step} loss={loss_val:.3e}")
                            
                            if loss_val + 1e-12 < best_loss:
                                best_loss = loss_val
                                stagnation = 0
                            else:
                                if (loss_prev - loss_val) < min_delta:
                                    stagnation += 1
                                else:
                                    stagnation = 0
                            
                            if best_loss < 1e-8 or stagnation >= patience:
                                stop_reason = "early_stop"
                                break
                            if time.time() - start_time > timeout_seconds:
                                print("â±ï¸ L-BFGS æ®µé”åˆ°è¶…æ™‚é™åˆ¶ï¼Œæå‰çµæŸ")
                                stop_reason = "timeout"
                                break
                        except Exception as e:
                            print(f"ğŸš¨ L-BFGSæ­¥é©Ÿå¤±æ•— (step={step}): {e}")
                            stop_reason = "error"
                            break
                
                # ä½¿ç”¨å¢å¼·çš„åƒæ•¸åŒæ­¥æ©Ÿåˆ¶
                sync_success = self._broadcast_model_parameters_with_verification()
                if not sync_success:
                    raise RuntimeError("åƒæ•¸åŒæ­¥å¤±æ•—")
                
                success = True
                
            else:
                # å–®GPUæ¨¡å¼
                for step in range(max_outer_steps):
                    try:
                        loss_prev = best_loss
                        loss_val = lbfgs.step(closure).item()
                        if step % log_interval == 0:
                            print(f"[L-BFGS] step={step} loss={loss_val:.3e}")
                        
                        if loss_val + 1e-12 < best_loss:
                            best_loss = loss_val
                            stagnation = 0
                        else:
                            if (loss_prev - loss_val) < min_delta:
                                stagnation += 1
                            else:
                                stagnation = 0
                        
                        if best_loss < 1e-8 or stagnation >= patience:
                            stop_reason = "early_stop"
                            break
                        if time.time() - start_time > timeout_seconds:
                            if self.rank == 0:
                                print("â±ï¸ L-BFGS æ®µé”åˆ°è¶…æ™‚é™åˆ¶ï¼Œæå‰çµæŸ")
                            stop_reason = "timeout"
                            break
                    except Exception as e:
                        if self.rank == 0:
                            print(f"ğŸš¨ L-BFGSæ­¥é©Ÿå¤±æ•— (step={step}): {e}")
                        stop_reason = "error"
                        break
                
                success = True
                
        except Exception as e:
            if self.rank == 0:
                print(f"ğŸš¨ L-BFGSåŸ·è¡Œå¤±æ•—: {e}")
            success = False
        
        # æ¢å¾©AdamWå„ªåŒ–å™¨ï¼ˆä¿æŒ stage lr / weight decayï¼‰
        current_lr = self.opt.param_groups[0]['lr'] if self.opt is not None else 1e-4
        wd = getattr(self, 'current_weight_decay', 0.0)
        try:
            self.build_adamw_optimizer(current_lr, wd)
        except Exception:
            # å›é€€æ™®é€šAdam
            self.opt = torch.optim.Adam(list(self.get_model(self.net).parameters()) + list(self.get_model(self.net_1).parameters()), lr=current_lr)
            for group in self.opt.param_groups:
                group['initial_lr'] = current_lr
        
        # æ®µå¾Œè§£é–/è§£å‡ï¼šå…ˆè§£å‡ä½†æš«ä¸é‡å»ºï¼Œæ¥è‘—çµ±ä¸€ä»¥ AdamW + scheduler é‡å»º
        self.lock_vis_t_minus = False
        try:
            self.defreeze_evm_net(self.stage_step, rebuild=False)
        except Exception:
            pass
        # AdamW å·²æ–¼ä¸Šæ–¹ build_adamw_optimizer é‡å»ºï¼›æ­¤è™•åªéœ€ scheduler é‡å»º
        self._rebuild_scheduler()
        
        # å¦‚æœL-BFGSå¤±æ•—ä¸”æœ‰å‚™ä»½ï¼Œå˜—è©¦æ¢å¾©Adamç‹€æ…‹
        if adam_state_backup is not None and not success:
            try:
                self.opt.load_state_dict(adam_state_backup)
                if self.rank == 0:
                    print("ğŸ”„ å·²æ¢å¾©Adamå„ªåŒ–å™¨ç‹€æ…‹")
            except Exception as e:
                if self.rank == 0:
                    print(f"âš ï¸ æ¢å¾©Adamç‹€æ…‹å¤±æ•—: {e}")
        
        if self.rank == 0:
            status = "æˆåŠŸ" if success else "å¤±æ•—ï¼Œå·²å›é€€"
            print(f"=== é›¢é–‹ {mode} L-BFGS æ®µ ({status}) ===")
            # è¨Šæ¯æç¤º
            if hasattr(self, 'config') and hasattr(self.config, 'training') and getattr(self.config.training, 'log_tips', True):
                if stop_reason == "timeout":
                    self._log_tip_once('lbfgs_timeout', "L-BFGS æ®µå›  timeout çµæŸï¼›å»ºè­° max_iterâ†’20 æˆ–ç¸®çŸ­ timeout_secondsã€‚")
                elif stop_reason == "early_stop":
                    self._log_tip_once('lbfgs_early_stop', "L-BFGS é€£çºŒå¤šæ¬¡æ”¹å–„å¾ˆå°è€Œæ—©åœï¼›å¯èª¿æ•´ tolerance æˆ–å¢åŠ  cooldown æ¸›å°‘é »åº¦ã€‚")
                elif stop_reason == "error":
                    self._log_tip_once('lbfgs_error', "L-BFGS æ®µå‡ºç¾éŒ¯èª¤ï¼›ç¢ºä¿æ®µå…§ FP32ã€å¯æš«åœ line search æˆ–é™ä½ max_iterã€‚")
        
        return best_loss

    def solve_Adam(self, loss_func, num_epoch=1000, batchsize=None, scheduler=None, profiler=None, start_epoch=0):
        # å­˜å‚¨å½“å‰schedulerä»¥ä¾¿åœ¨optimizeré‡å»ºæ—¶ä½¿ç”¨
        self.current_scheduler = scheduler
        self.current_scheduler_params = None
        # è¨˜éŒ„scheduleråç¨±ï¼ˆNone è¦–ç‚º Constantï¼‰ï¼Œä¾›é‡å»ºæ™‚åˆ¤æ–·æ˜¯å¦éœ€è¦éœé»˜è·³é
        try:
            self.current_scheduler_name = type(scheduler).__name__ if scheduler is not None else 'Constant'
        except Exception:
            self.current_scheduler_name = 'Constant'
        if scheduler is not None:
            # å­˜å‚¨schedulerçš„ç±»å‹å’Œå‚æ•°ä»¥ä¾¿é‡å»º
            self.current_scheduler_params = {
                'class': type(scheduler),
                'T_max': getattr(scheduler, 'T_max', None),
                'eta_min': getattr(scheduler, 'eta_min', None),
                'milestones': getattr(scheduler, 'milestones', None),
                'gamma': getattr(scheduler, 'gamma', None),
                'last_epoch': getattr(scheduler, 'last_epoch', -1)
            }
            # é¡å¤–æ”¯æ´ï¼šCosineAnnealingWarmRestarts èˆ‡ SequentialLRï¼ˆæš–å•Ÿå‹•ï¼‰
            try:
                import torch as _torch
                # CosineAnnealingWarmRestarts åƒæ•¸
                if isinstance(scheduler, _torch.optim.lr_scheduler.CosineAnnealingWarmRestarts):
                    self.current_scheduler_params.update({
                        'T_0': getattr(scheduler, 'T_0', None),
                        'T_mult': getattr(scheduler, 'T_mult', 1),
                        'eta_min': getattr(scheduler, 'eta_min', 0.0)
                    })
                # SequentialLR: ä¿å­˜å­scheduleré…ç½®
                if isinstance(scheduler, _torch.optim.lr_scheduler.SequentialLR):
                    sub_schedulers = getattr(scheduler, '_schedulers', [])
                    children = []
                    for sub in sub_schedulers:
                        entry = {'class': type(sub)}
                        if isinstance(sub, _torch.optim.lr_scheduler.LinearLR):
                            entry.update({
                                'start_factor': getattr(sub, 'start_factor', 1.0),
                                'end_factor': getattr(sub, 'end_factor', 1.0),
                                'total_iters': getattr(sub, 'total_iters', 0)
                            })
                        elif isinstance(sub, _torch.optim.lr_scheduler.CosineAnnealingWarmRestarts):
                            entry.update({
                                'T_0': getattr(sub, 'T_0', None),
                                'T_mult': getattr(sub, 'T_mult', 1),
                                'eta_min': getattr(sub, 'eta_min', 0.0)
                            })
                        elif isinstance(sub, _torch.optim.lr_scheduler.CosineAnnealingLR):
                            entry.update({
                                'T_max': getattr(sub, 'T_max', None),
                                'eta_min': getattr(sub, 'eta_min', 0.0)
                            })
                        elif isinstance(sub, _torch.optim.lr_scheduler.MultiStepLR):
                            entry.update({
                                'milestones': list(getattr(sub, 'milestones', [])),
                                'gamma': getattr(sub, 'gamma', 0.1)
                            })
                        children.append(entry)
                    self.current_scheduler_params.update({
                        'sequential': True,
                        'children': children,
                        'milestones': list(getattr(scheduler, 'milestones', [])) or []
                    })
            except Exception:
                pass
            
            # Debugè¼¸å‡ºç¢ºèªscheduleråƒæ•¸
            if self.rank == 0:
                scheduler_name = type(scheduler).__name__
                if scheduler_name == 'CosineAnnealingLR':
                    print(f"ğŸ”§ Scheduleråˆå§‹åŒ–: {scheduler_name}")
                    print(f"   - T_max: {scheduler.T_max}")
                    print(f"   - eta_min: {scheduler.eta_min:.2e}")
                    print(f"   - åˆå§‹lr: {self.opt.param_groups[0]['lr']:.2e}")
                elif scheduler_name == 'MultiStepLR':
                    print(f"ğŸ”§ Scheduleråˆå§‹åŒ–: {scheduler_name}")
                    print(f"   - milestones: {scheduler.milestones}")
                    print(f"   - gamma: {scheduler.gamma}")
                elif scheduler_name == 'CosineAnnealingWarmRestarts':
                    print(f"ğŸ”§ Scheduleråˆå§‹åŒ–: {scheduler_name}")
                    print(f"   - T_0: {getattr(scheduler,'T_0', None)}  T_mult: {getattr(scheduler,'T_mult', 1)}  eta_min: {getattr(scheduler,'eta_min', 0.0):.2e}")
                elif scheduler_name == 'SequentialLR':
                    print(f"ğŸ”§ Scheduleråˆå§‹åŒ–: {scheduler_name} (åŒ…å«warmup/SGDR)")
                else:
                    print(f"ğŸ”§ Scheduleråˆå§‹åŒ–: {scheduler_name}")
        
        # å•Ÿç”¨åˆå§‹å‡çµ
        self.freeze_evm_net(0)
        
        # ä½¿ç”¨å®Œæ•´æ•¸æ“šé€²è¡Œè¨“ç·´ï¼ˆä¸ä½¿ç”¨æ‰¹æ¬¡è™•ç†ï¼‰
        actual_data_points = self.x_f.shape[0]
        
        # è¨˜éŒ„éšæ®µé–‹å§‹æ™‚é–“å’Œå•Ÿå‹•å¥åº·ç›£æ§
        if self.rank == 0:
            self.stage_start_time = time.time()
            
            # è¨­ç½®è¨“ç·´é–‹å§‹æ™‚é–“ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡èª¿ç”¨æ™‚ï¼‰
            if self.training_start_time is None:
                self.training_start_time = time.time()
                
            # å•Ÿå‹•å¥åº·ç›£æ§

        
        if self.rank == 0:
            training_info = {
                "éšæ®µ": self.current_stage,
                "è¨“ç·´é»ç¸½æ•¸": f"{self.N_f:,}",
                "å¯¦éš›GPUæ•¸æ“šé»": f"{actual_data_points:,}",
                "è¨“ç·´æ¨¡å¼": "å…¨æ‰¹æ¬¡ (ç„¡DataLoader)",
                "ç¸½epochs": f"{num_epoch:,}",
                "DDPæ¨¡å¼": "å•Ÿç”¨" if self.world_size > 1 else "é—œé–‰",
                "æ•¸å€¼ç²¾åº¦": "Float32 (å®Œæ•´ç²¾åº¦)"
            }
            self.logger.info("=== è¨“ç·´é…ç½® (å…¨æ‰¹æ¬¡) ===")
            for key, value in training_info.items():
                self.logger.info(f"{key}: {value}")
            
            # GPUè¨˜æ†¶é«”ä¿¡æ¯
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated(self.device) / 1024**3
                memory_reserved = torch.cuda.memory_reserved(self.device) / 1024**3
                self.logger.info(f"GPUè¨˜æ†¶é«” - å·²åˆ†é…: {memory_allocated:.2f}GB, å·²ä¿ç•™: {memory_reserved:.2f}GB")
            self.logger.info("=" * 50)
        
        # æ™‚é–“ä¼°ç®—ç›¸é—œè®Šæ•¸
        # è¨ˆæ™‚åŒæ­¥é »ç‡ï¼ˆæ¸›å°‘é »ç¹åŒæ­¥é€ æˆçš„åœé “ï¼‰
        timing_sync_interval = 1000
        try:
            if hasattr(self, 'config') and hasattr(self.config, 'system'):
                timing_sync_interval = int(getattr(self.config.system, 'timing_sync_interval', 1000))
        except Exception:
            timing_sync_interval = 1000
        estimate_frequency = max(500, timing_sync_interval)  # èˆ‡åŒæ­¥é »ç‡å°é½Šï¼Œé¿å…é »ç¹ä¼°ç®—
        
        # æ»‘çª—èˆ‡æ­¥æ•¸è¨ˆæ•¸
        if not hasattr(self, 'global_step'):
            self.global_step = 0
        # é—œéµä¿®å¾©ï¼šæ¯å€‹æ–°éšæ®µéƒ½é‡ç½®stage_stepï¼Œä¸¦è¨˜éŒ„éšæ®µèµ·å§‹æ­¥æ•¸
        self.stage_step = start_epoch  # å¾start_epoché–‹å§‹ï¼Œè€Œä¸æ˜¯0
        self.stage_start_step = start_epoch  # è¨˜éŒ„ç•¶å‰éšæ®µèµ·å§‹æ­¥æ•¸ï¼Œç”¨æ–¼ç›¸å°æ­¥æ•¸è¨ˆç®—
        
        from collections import deque
        if not hasattr(self, 'stage_loss_deque') or self.stage_step == 0:
            self.stage_loss_deque = deque(maxlen=20000)
        if not hasattr(self, 'last_strategy_step'):
            self.last_strategy_step = -999999
        
        for epoch_id in range(start_epoch, num_epoch):
            # è¨˜éŒ„epoché–‹å§‹æ™‚é–“ï¼ˆåƒ…åœ¨éœ€è¦ç²¾ç¢ºè¨ˆæ™‚æ™‚åŒæ­¥GPUï¼‰
            if self.rank == 0:
                # ç¢ºå®šæ˜¯å¦éœ€è¦ç²¾ç¢ºè¨ˆæ™‚ï¼ˆå¯é…ç½®ï¼‰
                need_precise_timing = (
                    epoch_id % timing_sync_interval == 0 or
                    epoch_id == 0 or                     # é¦–å€‹epoch
                    epoch_id == num_epoch - 1 or         # æœ€å¾Œepoch
                    (epoch_id + 1) % timing_sync_interval == 0
                )
                
                if need_precise_timing and torch.cuda.is_available():
                    try:
                        torch.cuda.synchronize(self.device)
                    except Exception:
                        pass
                self.epoch_start_time = time.time()
            
            # ä¿®æ”¹å¾Œçš„å‹•æ…‹å‡çµé‚è¼¯ï¼šEVMåœ¨epoch 1-9999ä¿æŒå‡çµ
            if epoch_id != 0 and epoch_id % 10000 == 0:
                self.defreeze_evm_net(epoch_id)
            if epoch_id > 10000 and (epoch_id - 1) % 10000 == 0:
                self.freeze_evm_net(epoch_id)

            # æ¸…é™¤ä¸Šä¸€å€‹epochçš„æ¢¯åº¦
            self.opt.zero_grad(set_to_none=True)
            # ä½¿ç”¨æ¨™æº–float32ç²¾åº¦é€²è¡Œè¨ˆç®—
            loss, losses = loss_func()
            
            # æå¤±å€¼é©—è­‰å’ŒGPUè¨˜æ†¶é«”æª¢æŸ¥
            if not self.validate_loss_and_memory(loss, losses, epoch_id):
                self.logger.critical(f"Critical error at epoch {epoch_id}, stopping training...")
                return
            
            # æ¨™æº–ç²¾åº¦æ¢¯åº¦å›å‚³
            loss.backward()
            
            # è¨˜éŒ„æå¤±å€¼
            epoch_loss = loss.detach().item()
            epoch_losses = [
                losses[i] if isinstance(losses[i], (int, float)) else losses[i].detach().item()
                for i in range(len(losses))
            ]
            
            # æ¸…ç†å¼µé‡å¼•ç”¨
            del loss
            
            # æ¢¯åº¦è£å‰ªé¿å…æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(
                list(self.net.parameters()) + list(self.net_1.parameters()),
                max_norm=1.0
            )
            
            # æ›´æ–°åƒæ•¸

            
            # æª¢æŸ¥DDPç‹€æ…‹ä¸¦å˜—è©¦æ¢å¾©
            max_retry_attempts = 3
            retry_count = 0
            
            while retry_count < max_retry_attempts:
                try:
                    self.opt.step()
                    break  # æˆåŠŸåŸ·è¡Œï¼Œè·³å‡ºé‡è©¦å¾ªç’°
                    
                except RuntimeError as e:
                    retry_count += 1
                    error_msg = str(e)
                    
                    self.logger.ddp_error(error_msg, retry_count, max_retry_attempts)
                    
                    # æª¢æŸ¥ç‰¹å®šçš„DDPéŒ¯èª¤é¡å‹
                    if any(keyword in error_msg for keyword in [
                        "INTERNAL ASSERT FAILED", 
                        "unmarked_param_indices",
                        "bucket_boundaries_",
                        "DDP bucket",
                        "find_unused_parameters"
                    ]):
                        if retry_count < max_retry_attempts:
                            self.logger.info("   Attempting DDP recovery...")
                            # å˜—è©¦é‡å»ºoptimizeråƒæ•¸ç¾¤çµ„èˆ‡é‡æ–°åŒæ­¥
                            try:
                                self.rebuild_optimizer_groups()
                                self.opt.zero_grad(set_to_none=True)
                                if torch.cuda.is_available():
                                    torch.cuda.synchronize()
                            except Exception as recovery_e:
                                self.logger.error(f"   DDP recovery failed: {recovery_e}")
                        else:
                            self.logger.error(f"DDP recovery failed after {max_retry_attempts} attempts, skipping step...")
                            break
                    else:
                        # éDDPç›¸é—œéŒ¯èª¤ï¼Œç›´æ¥æ‹‹å‡º
                        raise e
                        
                except Exception as e:
                    self.logger.error(f"Unexpected error during optimizer step: {e}")
                    raise e
            
            # Scheduleræ­¥é€² - å¿…é ˆåœ¨optimizer.step()ä¹‹å¾Œ
            # å„ªå…ˆä½¿ç”¨å‚³å…¥çš„schedulerï¼Œé¿å…freeze/unfreezeå¾Œçš„schedulerå¤±æ•ˆå•é¡Œ
            # ä½¿ç”¨ç•¶å‰é‡å»ºå¾Œçš„schedulerå„ªå…ˆï¼Œé¿å…freeze/unfreezeå¾Œä»å¼•ç”¨èˆŠscheduler
            active_scheduler = self.current_scheduler if self.current_scheduler is not None else scheduler
            if active_scheduler:
                old_lr = self.opt.param_groups[0]['lr']
                active_scheduler.step()
                new_lr = self.opt.param_groups[0]['lr']
                
                # Debugè¼¸å‡ºæª¢æŸ¥scheduleræ˜¯å¦æ­£å¸¸å·¥ä½œï¼ˆé™é »ï¼‰
                if self.rank == 0 and epoch_id % timing_sync_interval == 0:
                    scheduler_name = type(active_scheduler).__name__
                    print(f"ğŸ”§ {scheduler_name} step {epoch_id}: lr {old_lr:.6f} -> {new_lr:.6f}")
                
                # é—œéµï¼šä¿å­˜schedulerçš„å®Œæ•´ç‹€æ…‹
                if self.current_scheduler_params is not None:
                    self.current_scheduler_params['last_epoch'] = active_scheduler.last_epoch
                    # å°æ–¼CosineAnnealingLRï¼Œé¡å¤–ä¿å­˜ç•¶å‰çš„å­¸ç¿’ç‡ç‹€æ…‹
                    if hasattr(active_scheduler, 'T_max'):
                        self.current_scheduler_params['current_lr'] = new_lr
            
            # æ­¥æ•¸èˆ‡æ»‘çª—
            self.global_step += 1
            self.stage_step += 1
            self.stage_loss_deque.append(epoch_loss)
            
            # ç›£æ¸¬ï¼šæ¢¯åº¦åˆ†ä½ˆèˆ‡æ–¹å‘ç©©å®šæ€§ï¼ˆæ¯ N æ­¥ï¼‰
            try:
                monitor_interval = 1000
                try:
                    if hasattr(self, 'config') and hasattr(self.config, 'system'):
                        monitor_interval = int(getattr(self.config.system, 'monitor_interval', 1000))
                except Exception:
                    monitor_interval = 1000
                if monitor_interval <= 0:
                    monitor_interval = 1000
                if (self.stage_step % monitor_interval) == 0:
                    grad_norms = []
                    flat_list = []
                    for p in list(self.get_model(self.net).parameters()) + list(self.get_model(self.net_1).parameters()):
                        if p.grad is not None:
                            g = p.grad.detach()
                            grad_norms.append(g.norm().item())
                            # åƒ…åœ¨ç›£æ¸¬æ­¥æ‰åš CPU æ‹·è²
                            flat_list.append(g.view(-1).float().cpu())
                    if grad_norms:
                        import numpy as _np
                        med = float(_np.median(grad_norms))
                        q1 = float(_np.percentile(grad_norms, 25))
                        q3 = float(_np.percentile(grad_norms, 75))
                        self.grad_median = med
                        self.grad_iqr = max(q3 - q1, 0.0)
                        if not hasattr(self, 'grad_baseline'):
                            self.grad_baseline = med
                        else:
                            if self.stage_step < 5000:
                                self.grad_baseline = 0.99 * self.grad_baseline + 0.01 * med
                        if flat_list:
                            g_flat = torch.cat(flat_list)
                            if hasattr(self, 'prev_grad_flat') and self.prev_grad_flat is not None:
                                denom = (g_flat.norm() * self.prev_grad_flat.norm()).item() + 1e-12
                                cos = float((g_flat @ self.prev_grad_flat).item() / denom)
                                self.grad_cos_ema = 0.9 * float(getattr(self, 'grad_cos_ema', 0.0)) + 0.1 * cos
                            self.prev_grad_flat = g_flat
            except Exception:
                pass

            # ç›£æ¸¬ï¼šäººå·¥é»æ»¯ä¸Šé™å‘½ä¸­ç‡ï¼ˆP95ï¼‰ï¼ˆæ¯ N æ­¥ï¼‰
            try:
                monitor_interval = 1000
                try:
                    if hasattr(self, 'config') and hasattr(self.config, 'system'):
                        monitor_interval = int(getattr(self.config.system, 'monitor_interval', 1000))
                except Exception:
                    monitor_interval = 1000
                if monitor_interval <= 0:
                    monitor_interval = 1000
                if (self.stage_step % monitor_interval) == 0:
                    if hasattr(self, 'vis_t_minus_gpu') and self.vis_t_minus_gpu is not None:
                        cap_val = float(self.beta) / float(self.Re) if self.beta is not None else (1.0 / float(self.Re))
                        if cap_val > 0:
                            sl = min(self.vis_t_minus_gpu.shape[0], 4096)
                            ratio = (self.vis_t_minus_gpu[:sl] / cap_val).clamp(max=1.0).detach().float().cpu()
                            self.vis_cap_p95 = float(torch.quantile(ratio.view(-1), 0.95).item())
            except Exception:
                pass
            # åˆ†ä½ˆå¼L-BFGSè§¸ç™¼æª¢æ¸¬
            trigger_lbfgs = self._check_distributed_lbfgs_trigger()
            # æç¤ºï¼šé•·æ™‚é–“æœªè§¸ç™¼ or äººå·¥é»æ»¯åé«˜
            try:
                cfg = getattr(self, 'config', None)
                lb = getattr(cfg.training, 'lbfgs', None) if cfg and hasattr(cfg, 'training') else None
                group_idx = self._stage_group_index()
                W_list = getattr(lb, 'trigger_window_per_stage', [5000, 7500, 10000]) if lb else [5000, 7500, 10000]
                W = int(W_list[min(group_idx, len(W_list)-1)])
                cooldown = int(getattr(lb, 'cooldown_steps', 5000)) if lb else 5000
                # é•·æ™‚é–“æœªè§¸ç™¼
                if (self.stage_step - self.last_strategy_step) > (2 * W):
                    self._log_tip_once('not_trigger', f"L-BFGS æœªè§¸ç™¼å·²è¶…é {2*W} æ­¥ï¼›å¯é™ä½ min_improve_pct æˆ–ç¸®çŸ­ cooldown ({cooldown}).")
                # äººå·¥é»æ»¯åé«˜
                if float(getattr(self, 'vis_cap_p95', 0.0)) > 0.7:
                    # ç©ç´¯2000æ­¥ä»¥ä¸Šå†æç¤º
                    if not hasattr(self, '_vis_high_steps'):
                        self._vis_high_steps = 0
                    self._vis_high_steps += 1
                    if self._vis_high_steps > 2000:
                        self._log_tip_once('vis_cap_high', "äººå·¥é»æ»¯ä½¿ç”¨ç‡åé«˜ï¼ˆP95>0.7ï¼‰ï¼›å»ºè­°å°‡ last_layer_scale_evm èª¿è‡³ 0.05 æˆ–é™ä½ Î±_evmã€‚")
                else:
                    self._vis_high_steps = 0
            except Exception:
                pass
            if trigger_lbfgs:
                # å†·å»è¨˜éŒ„
                self.prev_strategy_step = self.last_strategy_step
                self.last_strategy_step = self.stage_step
                # ä½¿ç”¨é…ç½®åƒæ•¸å•Ÿå‹•L-BFGSæ®µ
                self.train_with_lbfgs_segment()
                if self.rank == 0:
                    print("âœ… é›¢é–‹ L-BFGS æ®µï¼Œæ¢å¾© Adam")
                # æç¤ºï¼šéæ–¼é »ç¹ï¼ˆä½¿ç”¨ç›¸å°æ­¥æ•¸ï¼‰
                try:
                    cfg = getattr(self, 'config', None)
                    lb = getattr(cfg.training, 'lbfgs', None) if cfg and hasattr(cfg, 'training') else None
                    cooldown = int(getattr(lb, 'cooldown_steps', 5000)) if lb else 5000
                    stage_start_step = getattr(self, 'stage_start_step', 0)
                    current_relative_step = self.last_strategy_step - stage_start_step
                    prev_relative_step = self.prev_strategy_step - stage_start_step
                    if (current_relative_step - prev_relative_step) < (2 * cooldown):
                        self._log_tip_once('too_frequent', f"L-BFGS è§¸ç™¼éæ–¼é »ç¹ï¼›å»ºè­°æé«˜ min_improve_pct æˆ–å¢å¤§ cooldownï¼ˆç›®å‰ {cooldown}ï¼‰ã€‚")
                except Exception:
                    pass
                # æ®µå¾Œå„ªåŒ–å™¨èˆ‡schedulerå·²åœ¨æ®µå…§æ¢å¾©
            # æ™‚é–“è¿½è¹¤å’Œé ä¼°ï¼ˆåªåœ¨rank 0åŸ·è¡Œï¼›åƒ…åœ¨éœ€è¦ç²¾ç¢ºè¨ˆæ™‚æ™‚åŒæ­¥GPUï¼‰
            if self.rank == 0:
                # ç¢ºå®šæ˜¯å¦éœ€è¦ç²¾ç¢ºè¨ˆæ™‚ï¼ˆèˆ‡é–‹å§‹æ™‚ç›¸åŒçš„é‚è¼¯ï¼‰
                need_precise_timing = (
                    epoch_id % 100 == 0 or               # æ¯100 epochsé€²è¡Œæ™‚é–“é ä¼°
                    epoch_id == 0 or                     # é¦–å€‹epoch
                    epoch_id == num_epoch - 1 or         # æœ€å¾Œepoch
                    (epoch_id + 1) % 1000 == 0           # consoleè¼¸å‡ºæ™‚éœ€è¦ç²¾ç¢ºæ™‚é–“
                )
                
                if need_precise_timing and torch.cuda.is_available():
                    try:
                        torch.cuda.synchronize(self.device)
                    except Exception:
                        pass
                epoch_end_time = time.time()
                epoch_time = epoch_end_time - self.epoch_start_time

            # æ™‚é–“è¿½è¹¤å’Œé ä¼°ï¼ˆåªåœ¨rank 0åŸ·è¡Œï¼›åƒ…åœ¨éœ€è¦ç²¾ç¢ºè¨ˆæ™‚æ™‚åŒæ­¥GPUï¼‰
            if self.rank == 0:
                # å¥åº·æª¢æŸ¥æ¢ä»¶åˆ¤æ–· (éœ€è¦æå‰ä»¥ç¢ºå®šæ˜¯å¦éœ€è¦ç²¾ç¢ºè¨ˆæ™‚)
                should_monitor = False
                if epoch_id <= 100 and epoch_id % 10 == 0:  # å‰100å€‹epochå¯†é›†ç›£æ¸¬
                    should_monitor = True
                elif epoch_id in [300000, 600000, 900000, 1200000, 1500000]:  # éšæ®µè½‰æ›é»
                    should_monitor = True
                elif epoch_id > 1000 and epoch_id % 10000 == 0:  # å®šæœŸæª¢æŸ¥
                    should_monitor = True
                
                # ç¢ºå®šæ˜¯å¦éœ€è¦ç²¾ç¢ºè¨ˆæ™‚
                need_precise_timing = (
                    epoch_id % 100 == 0 or               # æ¯100 epochsé€²è¡Œæ™‚é–“é ä¼°
                    epoch_id == 0 or                     # é¦–å€‹epoch
                    epoch_id == num_epoch - 1 or         # æœ€å¾Œepoch
                    (epoch_id + 1) % 1000 == 0 or        # consoleè¼¸å‡ºæ™‚éœ€è¦ç²¾ç¢ºæ™‚é–“
                    should_monitor                       # å¥åº·æª¢æŸ¥æ™‚
                )
                
                if need_precise_timing and torch.cuda.is_available():
                    try:
                        torch.cuda.synchronize(self.device)
                    except Exception:
                        pass
                epoch_end_time = time.time()
                epoch_time = epoch_end_time - self.epoch_start_time
                
                # é™åˆ¶epoch_timeså¤§å°ä»¥é˜²è¨˜æ†¶é«”æ´©æ¼
                self.epoch_times.append(epoch_time)
                if len(self.epoch_times) > 1000:  # åªä¿ç•™æœ€è¿‘1000å€‹epochçš„æ™‚é–“
                    self.epoch_times = self.epoch_times[-500:]  # åˆªé™¤ä¸€åŠèˆŠæ•¸æ“šï¼Œä¿æŒé«˜æ•ˆ
                
                # è¨˜éŒ„åˆ°TensorBoardï¼ˆé™é »å¯«å…¥ï¼‰
                if self.tb_writer is not None and (epoch_id % max(1, self.tb_interval) == 0 or epoch_id in (0, num_epoch-1)):
                    global_step = self.global_step_offset + epoch_id
                    
                    self.safe_tensorboard_log('Loss/Total', epoch_loss, global_step)
                    self.safe_tensorboard_log('Loss/Equation_Combined', epoch_losses[0], global_step)
                    self.safe_tensorboard_log('Loss/Boundary', epoch_losses[1], global_step)
                    self.safe_tensorboard_log('Loss/Supervised', epoch_losses[2], global_step)
                    self.safe_tensorboard_log('Loss/Equation_NS_X', epoch_losses[3], global_step)
                    self.safe_tensorboard_log('Loss/Equation_NS_Y', epoch_losses[4], global_step)
                    self.safe_tensorboard_log('Loss/Equation_Continuity', epoch_losses[5], global_step)
                    self.safe_tensorboard_log('Loss/Equation_EntropyResidual', epoch_losses[6], global_step)
                    self.safe_tensorboard_log('Training/LearningRate', self.opt.param_groups[0]['lr'], global_step)
                    # è¨˜éŒ„ç•¶å‰ weight decayï¼ˆä¸»åƒæ•¸çµ„ï¼‰
                    try:
                        wd_val = float(getattr(self, 'current_weight_decay', 0.0))
                        if wd_val <= 0.0:
                            # è‹¥ current_weight_decay æœªè¨­æˆ–ç‚º0ï¼Œå˜—è©¦å¾åƒæ•¸çµ„æª¢æ¸¬
                            for _pg in self.opt.param_groups:
                                if _pg.get('weight_decay', 0.0) > 0:
                                    wd_val = float(_pg['weight_decay'])
                                    break
                        self.safe_tensorboard_log('Training/WeightDecay', wd_val, global_step)
                    except Exception:
                        pass
                    self.safe_tensorboard_log('Training/EpochTime', epoch_time, global_step)
                    self.safe_tensorboard_log('Training/Alpha_EVM', self.alpha_evm, global_step)
                    
                    # GPUè¨˜æ†¶é«”ä½¿ç”¨ï¼ˆé™é »ï¼‰
                    if torch.cuda.is_available():
                        memory_allocated = torch.cuda.memory_allocated(self.device) / 1024**3
                        self.safe_tensorboard_log('System/GPU_Memory_GB', memory_allocated, global_step)
                
                # å¥åº·æª¢æŸ¥ï¼ˆé™é »ï¼‰
                if should_monitor and (epoch_id % (10 * timing_sync_interval) == 0 or epoch_id in (0, num_epoch-1)):
                    self.logger.info(f"ğŸ” Enhanced Health Check - Epoch {epoch_id}")
                    self.check_tanh_saturation(epoch_id)

                # è¨˜æ†¶é«”ç›£æ§ (æ¯50å€‹epochæª¢æŸ¥ä¸€æ¬¡)

            
            # æ¯1000å€‹epochè¼¸å‡ºä¸€æ¬¡è¨“ç·´ç‹€æ³ï¼Œé¦–å€‹epochä¹Ÿè¦è¼¸å‡º
            if self.rank == 0 and (epoch_id == 0 or (epoch_id + 1) % 1000 == 0 or epoch_id == num_epoch - 1):
                self.print_log_full_batch_with_time_estimate(epoch_loss, epoch_losses, epoch_id, num_epoch, actual_data_points)
                
                # æ¯1000å€‹epochè¼¸å‡ºå¥åº·å’Œè¨˜æ†¶é«”å ±å‘Š
                
                # æ¯1000å€‹epochæª¢æŸ¥tanhé£½å’Œåº¦
                self.check_tanh_saturation(epoch_id)


            # Save checkpoint
            if self.rank == 0 and (epoch_id > 0 and epoch_id % self.checkpoint_freq == 0 or epoch_id == num_epoch - 1):
                self.save_checkpoint(epoch_id, self.opt)


        # éšæ®µçµæŸå¾Œæ›´æ–°global step offset
        if self.rank == 0:
            self.global_step_offset += num_epoch
            
            # éšæ®µçµæŸæ™‚çš„æœ€çµ‚æ¸…ç†å’Œçµ±è¨ˆ

    
    def freeze_evm_net(self, epoch_id):
        """
        å‡çµEVMç¶²è·¯åƒæ•¸ - ä¿æŒscheduleré€£çºŒæ€§
        """
        if self.rank == 0:
            print(f"[Epoch {epoch_id}] Freezing EVM network parameters (ä¿æŒscheduleré€£çºŒæ€§)")
        
        # å‡çµnet_1çš„æ‰€æœ‰åƒæ•¸
        for param in self.net_1.parameters():
            param.requires_grad = False
        # é‡å»º AdamW ä»¥ç§»é™¤å‡çµåƒæ•¸
        try:
            self.rebuild_after_structure_change()
        except Exception:
            pass
        if self.rank == 0 and self.opt is not None:
            total_trainable = sum(p.numel() for g in self.opt.param_groups for p in g['params'])
            print(f"  Active parameters (net only): {total_trainable}")

    def defreeze_evm_net(self, epoch_id, rebuild: bool = True):
        """
        è§£å‡EVMç¶²è·¯åƒæ•¸
        rebuild=True æ™‚æœƒå‘¼å« rebuild_after_structure_change ä»¥é‡å»º AdamW / scheduler
        """
        if self.rank == 0:
            print(f"[Epoch {epoch_id}] Unfreezing EVM network parameters (ä¿æŒscheduleré€£çºŒæ€§)")
        # è§£å‡ net_1 åƒæ•¸
        for param in self.net_1.parameters():
            param.requires_grad = True
        if rebuild:
            try:
                self.rebuild_after_structure_change()
            except Exception:
                pass
        if self.rank == 0 and self.opt is not None:
            total_trainable = sum(p.numel() for p in list(self.get_model(self.net).parameters()) if p.requires_grad) + \
                               sum(p.numel() for p in list(self.get_model(self.net_1).parameters()) if p.requires_grad)
            print(f"  Active parameters (net + net_1): {total_trainable}")

    def _rebuild_scheduler(self):
        """é‡å»ºschedulerä»¥ç»‘å®šæ–°çš„optimizerï¼Œç¢ºä¿å­¸ç¿’ç‡é€£çºŒæ€§"""
        if self.current_scheduler is None or self.current_scheduler_params is None:
            # è‹¥ç‚º Constantï¼ˆæœªé…ç½®schedulerï¼‰ï¼Œéœé»˜è·³éä¸¦ä¿æŒç›®å‰lrï¼Œä¸è¦–ç‚ºè­¦å‘Š
            if getattr(self, 'current_scheduler_name', 'Constant') == 'Constant':
                if self.rank == 0:
                    print("  â„¹ï¸ è·³éscheduleré‡å»ºï¼šæœªé…ç½®schedulerï¼ˆConstantï¼‰ï¼Œä¿æŒlré€£çºŒæ€§")
                return
            else:
                if self.rank == 0:
                    print("  Warning: ç„¡æ³•é‡å»ºscheduler - ç¼ºå°‘åƒæ•¸")
                return
            
        try:
            # ä¿å­˜ç•¶å‰å­¸ç¿’ç‡ä»¥ç¢ºä¿é€£çºŒæ€§
            current_lr = self.opt.param_groups[0]['lr']
            
            # ç¡®ä¿optimizerå‚æ•°ç»„æœ‰initial_lr
            for group in self.opt.param_groups:
                if 'initial_lr' not in group:
                    group['initial_lr'] = group['lr']
            
            scheduler_class = self.current_scheduler_params['class']
            
            # é—œéµä¿®å¾©ï¼šé‡å»ºæ™‚ä¸æ”¹è®Šç•¶å‰å­¸ç¿’ç‡ï¼Œä¿æŒåŸæœ‰é€²åº¦
            if scheduler_class.__name__ == 'CosineAnnealingLR':
                # å‰µå»ºæ–°schedulerï¼Œä½†ç«‹å³è¨­ç½®åˆ°ç•¶å‰å­¸ç¿’ç‡
                self.current_scheduler = scheduler_class(
                    self.opt, 
                    T_max=self.current_scheduler_params['T_max'],
                    eta_min=self.current_scheduler_params['eta_min'],
                    last_epoch=-1  # è®“schedulerå¾åˆå§‹ç‹€æ…‹é–‹å§‹
                )
                
                # æ‰‹å‹•è¨­ç½®å­¸ç¿’ç‡ä¿æŒé€£çºŒæ€§
                for group in self.opt.param_groups:
                    group['lr'] = current_lr
                    
                # æ›´æ–°schedulerçš„last_epochä»¥åŒ¹é…ç•¶å‰é€²åº¦
                stage_epoch = self.stage_step if hasattr(self, 'stage_step') else 0
                self.current_scheduler.last_epoch = stage_epoch - 1
                
                if self.rank == 0:
                    print(f"  âœ… é‡å»ºCosineAnnealingLR: ä¿æŒlr={current_lr:.6f}, stage_epoch={stage_epoch}")
                    
            elif scheduler_class.__name__ == 'MultiStepLR':
                # å‰µå»ºæ–°schedulerä¸¦è¨­ç½®ç•¶å‰å­¸ç¿’ç‡
                self.current_scheduler = scheduler_class(
                    self.opt,
                    milestones=self.current_scheduler_params['milestones'],
                    gamma=self.current_scheduler_params['gamma'],
                    last_epoch=-1
                )
                
                # æ‰‹å‹•è¨­ç½®å­¸ç¿’ç‡ä¿æŒé€£çºŒæ€§
                for group in self.opt.param_groups:
                    group['lr'] = current_lr
                    
                stage_epoch = self.stage_step if hasattr(self, 'stage_step') else 0
                self.current_scheduler.last_epoch = stage_epoch - 1
                
                if self.rank == 0:
                    print(f"  âœ… é‡å»ºMultiStepLR: ä¿æŒlr={current_lr:.6f}, stage_epoch={stage_epoch}")
            elif scheduler_class.__name__ == 'CosineAnnealingWarmRestarts':
                # é‡å»ºCAWRï¼Œä¿æŒå­¸ç¿’ç‡é€£çºŒæ€§
                T_0 = self.current_scheduler_params.get('T_0', 1000)
                T_mult = self.current_scheduler_params.get('T_mult', 1)
                eta_min = self.current_scheduler_params.get('eta_min', 0.0)
                self.current_scheduler = scheduler_class(
                    self.opt,
                    T_0=T_0,
                    T_mult=T_mult,
                    eta_min=eta_min
                )
                # æ‰‹å‹•è¨­ç½®å­¸ç¿’ç‡ä¿æŒé€£çºŒæ€§
                for group in self.opt.param_groups:
                    group['lr'] = current_lr
                stage_epoch = self.stage_step if hasattr(self, 'stage_step') else 0
                self.current_scheduler.last_epoch = stage_epoch - 1
                if self.rank == 0:
                    print(f"  âœ… é‡å»ºCosineAnnealingWarmRestarts: ä¿æŒlr={current_lr:.6f}, stage_epoch={stage_epoch}")
            elif scheduler_class.__name__ == 'SequentialLR':
                # é‡å»ºé †åºèª¿åº¦å™¨ï¼šæ”¯æ´ LinearLR -> CosineAnnealingWarmRestarts çµ„åˆ
                children = self.current_scheduler_params.get('children', [])
                rebuilt = []
                import torch as _torch
                for ch in children:
                    cls = ch.get('class')
                    name = cls.__name__ if hasattr(cls, '__name__') else str(cls)
                    if name == 'LinearLR':
                        rebuilt.append(_torch.optim.lr_scheduler.LinearLR(
                            self.opt,
                            start_factor=ch.get('start_factor', 1.0),
                            end_factor=ch.get('end_factor', 1.0),
                            total_iters=ch.get('total_iters', 0)
                        ))
                    elif name == 'CosineAnnealingWarmRestarts':
                        rebuilt.append(_torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
                            self.opt,
                            T_0=ch.get('T_0', 1000),
                            T_mult=ch.get('T_mult', 1),
                            eta_min=ch.get('eta_min', 0.0)
                        ))
                    elif name == 'CosineAnnealingLR':
                        rebuilt.append(_torch.optim.lr_scheduler.CosineAnnealingLR(
                            self.opt,
                            T_max=ch.get('T_max', 1000),
                            eta_min=ch.get('eta_min', 0.0)
                        ))
                    elif name == 'MultiStepLR':
                        rebuilt.append(_torch.optim.lr_scheduler.MultiStepLR(
                            self.opt,
                            milestones=ch.get('milestones', []),
                            gamma=ch.get('gamma', 0.1)
                        ))
                    else:
                        # ä¸èªè­˜çš„å­schedulerï¼Œå›é€€ç‚ºæ†å®š
                        rebuilt.append(_torch.optim.lr_scheduler.ConstantLR(self.opt, factor=1.0, total_iters=1))
                # ä¿®æ­£milestonesé‚è¼¯ï¼šç¢ºä¿ç¬¦åˆPyTorch SequentialLRè¦æ±‚
                ms = self.current_scheduler_params.get('milestones', [])
                if len(ms) == 0 and len(rebuilt) >= 2:
                    # SGDRçµ„åˆï¼šwarmup + main schedulerï¼Œéœ€è¦æ­£ç¢ºçš„milestone
                    if hasattr(rebuilt[0], 'total_iters'):
                        ms = [rebuilt[0].total_iters]
                    else:
                        # å›é€€é è¨­å€¼ï¼šå‡è¨­warmupä½”å‰10%
                        total_epochs = getattr(self, 'epochs_per_stage', 300000)
                        ms = [int(0.1 * total_epochs)]
                elif len(ms) == 0:
                    # å–®scheduleræƒ…æ³ï¼Œä¸éœ€è¦milestone
                    ms = []
                
                # é©—è­‰milestonesæ•¸é‡ï¼šlen(schedulers) = len(milestones) + 1
                if len(rebuilt) != len(ms) + 1:
                    if self.rank == 0:
                        print(f"  âš ï¸ Milestoneèª¿æ•´: schedulers={len(rebuilt)}, milestones={len(ms)} -> {len(rebuilt)-1}")
                    ms = ms[:len(rebuilt)-1] if len(ms) >= len(rebuilt) else ms + [1000] * (len(rebuilt) - len(ms) - 1)
                
                self.current_scheduler = _torch.optim.lr_scheduler.SequentialLR(
                    self.opt,
                    schedulers=rebuilt,
                    milestones=ms
                )
                # ä¿æŒç•¶å‰å­¸ç¿’ç‡èˆ‡é€²åº¦
                for group in self.opt.param_groups:
                    group['lr'] = current_lr
                stage_epoch = self.stage_step if hasattr(self, 'stage_step') else 0
                self.current_scheduler.last_epoch = stage_epoch - 1
                if self.rank == 0:
                    print(f"  âœ… é‡å»ºSequentialLR: ä¿æŒlr={current_lr:.6f}, stage_epoch={stage_epoch}")
            else:
                # å¯¹äºå…¶ä»–ç±»å‹çš„schedulerï¼Œå°è¯•é€šç”¨é‡å»º
                self.current_scheduler = scheduler_class(self.opt)
                
                # ä¿æŒç•¶å‰å­¸ç¿’ç‡
                for group in self.opt.param_groups:
                    group['lr'] = current_lr
                    
                if self.rank == 0:
                    print(f"  âœ… é‡å»º{scheduler_class.__name__}: ä¿æŒlr={current_lr:.6f}")
                
        except Exception as e:
            if self.rank == 0:
                print(f"  âŒ Scheduleré‡å»ºå¤±æ•—: {e}")
            self.current_scheduler = None

    def safe_tensorboard_log(self, tag, value, global_step):
        """å®‰å…¨çš„TensorBoardè¨˜éŒ„å‡½æ•¸withéŒ¯èª¤è™•ç†"""
        if self.tb_writer is not None:
            try:
                # æª¢æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆ
                if value is None or not isinstance(value, (int, float)):
                    self.logger.warning(f"Invalid value for TensorBoard tag '{tag}': {value}")
                    return
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºNaNæˆ–Inf
                if isinstance(value, float) and (math.isnan(value) or math.isinf(value)):
                    self.logger.warning(f"NaN/Inf value detected for TensorBoard tag '{tag}': {value}")
                    return
                
                # è¨˜éŒ„åˆ°TensorBoard
                self.tb_writer.add_scalar(tag, value, global_step)
                
            except Exception as e:
                self.logger.warning(f"TensorBoard logging error for tag '{tag}': {e}")

    def validate_loss_and_memory(self, loss, losses, epoch_id):
        """æå¤±å€¼é©—è­‰å’ŒGPUè¨˜æ†¶é«”æª¢æŸ¥"""
        try:
            # æª¢æŸ¥ä¸»æå¤±å€¼
            loss_value = loss.detach().item() if hasattr(loss, 'detach') else loss
            
            if math.isnan(loss_value) or math.isinf(loss_value):
                self.logger.loss_validation_error(epoch_id, loss_value, "main")
                return False
            
            if loss_value > 1e10:  # æå¤±å€¼éå¤§
                self.logger.warning(f"Extremely large loss detected at epoch {epoch_id}: {loss_value}")
            
            # æª¢æŸ¥å„å€‹æå¤±çµ„ä»¶
            for i, component_loss in enumerate(losses):
                comp_value = component_loss.detach().item() if hasattr(component_loss, 'detach') else component_loss
                
                if math.isnan(comp_value) or math.isinf(comp_value):
                    self.logger.loss_validation_error(epoch_id, comp_value, f"component_{i}")
                    return False
            
            # GPUè¨˜æ†¶é«”æª¢æŸ¥
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated(self.device) / 1024**3
                memory_reserved = torch.cuda.memory_reserved(self.device) / 1024**3
                
                # æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨æ˜¯å¦éé«˜ï¼ˆè¶…éå¯ç”¨è¨˜æ†¶é«”çš„90%ï¼‰
                total_memory = torch.cuda.get_device_properties(self.device).total_memory / 1024**3
                if memory_allocated > total_memory * 0.9:
                    self.logger.memory_warning(memory_allocated, total_memory)
                    self.logger.info("   Attempting memory cleanup...")
                    
                    # å˜—è©¦æ¸…ç†GPUè¨˜æ†¶é«”
                    torch.cuda.empty_cache()
                    
                    # å†æ¬¡æª¢æŸ¥
                    memory_allocated_after = torch.cuda.memory_allocated(self.device) / 1024**3
                    if memory_allocated_after > total_memory * 0.95:
                        self.logger.critical(f"Critical GPU memory usage: {memory_allocated_after:.2f}GB / {total_memory:.2f}GB")
                        return False
            
            return True
            
        except Exception as e:
            self.logger.warning(f"Error in loss/memory validation at epoch {epoch_id}: {e}")
            return True  # é©—è­‰éŒ¯èª¤æ™‚ç¹¼çºŒè¨“ç·´

    def rebuild_optimizer_groups(self):
        """çµ±ä¸€é‡å»º AdamW åƒæ•¸ç¾¤çµ„ (DDP æ¢å¾© / çµæ§‹è®Šæ›´)ã€‚"""
        try:
            if self.opt is None or not hasattr(self, 'current_weight_decay'):
                # è‹¥å°šæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨é è¨­ lr / wd
                self.build_adamw_optimizer(1e-3, getattr(self, 'current_weight_decay', 0.0))
                return
            current_lr = self.opt.param_groups[0].get('lr', 1e-3)
            wd = getattr(self, 'current_weight_decay', 0.0)
            self.build_adamw_optimizer(current_lr, wd)
            if self.rank == 0:
                print(f"   âœ… DDPæ¢å¾©: é‡æ–°æ§‹å»º AdamW (lr={current_lr:.2e}, wd={wd})")
        except Exception as e:
            if self.rank == 0:
                print(f"   âŒ DDPæ¢å¾©é‡å»ºå¤±æ•—: {e}")
            raise e

    def print_log_full_batch_with_time_estimate(self, loss, losses, epoch_id, num_epoch, data_points):
        """æ‰“å°è¨“ç·´æ—¥èªŒåŒ…å«è©³ç´°æ™‚é–“é ä¼°å’Œæ”¶æ–‚åˆ†æ"""
        current_lr = self.opt.param_groups[0]['lr']
        
        # è¨ˆç®—æ™‚é–“çµ±è¨ˆ
        if len(self.epoch_times) > 10:  # è‡³å°‘éœ€è¦10å€‹epochä¾†è¨ˆç®—å¯é çš„é ä¼°
            # ä½¿ç”¨æœ€è¿‘50å€‹epochçš„å¹³å‡æ™‚é–“ï¼Œæ›´æº–ç¢ºåæ˜ ç•¶å‰é€Ÿåº¦
            recent_epochs = min(50, len(self.epoch_times))
            avg_epoch_time = np.mean(self.epoch_times[-recent_epochs:])
            
            # é ä¼°å‰©é¤˜æ™‚é–“
            remaining_epochs = num_epoch - (epoch_id + 1)
            estimated_remaining_time = remaining_epochs * avg_epoch_time
            
            # è¨ˆç®—éšæ®µç¸½æ™‚é–“é ä¼°
            stage_elapsed = time.time() - self.stage_start_time
            stage_progress = (epoch_id + 1) / num_epoch
            stage_total_estimated = stage_elapsed / stage_progress if stage_progress > 0 else 0
            stage_eta = stage_total_estimated - stage_elapsed
            
            # è¨ˆç®—æ•´å€‹è¨“ç·´çš„é€²åº¦ï¼ˆå¦‚æœæ˜¯å¤šéšæ®µè¨“ç·´ï¼‰
            if hasattr(self, 'training_start_time') and self.training_start_time:
                total_training_time = time.time() - self.training_start_time
            else:
                total_training_time = stage_elapsed
            
            # è¨ˆç®—epochè™•ç†é€Ÿåº¦
            epochs_per_minute = 60.0 / avg_epoch_time if avg_epoch_time > 0 else 0
            
            # æå¤±æ”¶æ–‚åˆ†æ
            convergence_info = self._analyze_convergence_trend(losses)
            
            # æ ¼å¼åŒ–æ™‚é–“é¡¯ç¤º
            def format_time(seconds):
                if seconds < 60:
                    return f"{seconds:.1f}s"
                elif seconds < 3600:
                    return f"{seconds//60:.0f}m {seconds%60:.0f}s"
                elif seconds < 86400:
                    hours = seconds // 3600
                    minutes = (seconds % 3600) // 60
                    return f"{hours:.0f}h {minutes:.0f}m"
                else:
                    days = seconds // 86400
                    hours = (seconds % 86400) // 3600
                    return f"{days:.0f}d {hours:.0f}h"
            
            # é¡¯ç¤ºè©³ç´°è¨“ç·´å ±å‘Š
            print(f"\n{'='*100}")
            print(f"ğŸ”¥ {self.current_stage} | è¨“ç·´é€²åº¦å ±å‘Š")
            print(f"{'='*100}")
            
            # é€²åº¦ä¿¡æ¯
            progress_bar_length = 40
            filled_length = int(progress_bar_length * (epoch_id + 1) / num_epoch)
            bar = 'â–ˆ' * filled_length + '-' * (progress_bar_length - filled_length)
            
            print(f"ğŸ“Š é€²åº¦: [{bar}] {(epoch_id + 1)/num_epoch*100:.1f}%")
            print(f"   Epoch: {epoch_id + 1:,} / {num_epoch:,}")
            print(f"   è³‡æ–™é»: {data_points:,} | å­¸ç¿’ç‡: {current_lr:.2e}")
            
            # æå¤±ä¿¡æ¯
            print(f"\nğŸ“ˆ æå¤±ç‹€æ³:")
            print(f"   ç¸½æå¤±:   {loss:.3e} {convergence_info['trend_symbol']}")
            print(f"   æ–¹ç¨‹ç¸½æå¤±: {losses[0]:.3e}")
            print(f"   ç›£ç£æå¤±: {losses[2]:.3e}")
            print(f"   é‚Šç•Œæå¤±: {losses[1]:.3e}")
            print(f"   Navier-Stokes Xæå¤±: {losses[3]:.3e}")
            print(f"   Navier-Stokes Yæå¤±: {losses[4]:.3e}")
            print(f"   é€£çºŒæ€§æ–¹ç¨‹æå¤±: {losses[5]:.3e}")
            print(f"   ç†µæ®˜å·®æå¤±: {losses[6]:.3e}")
            print(f"   æ”¶æ–‚è¶¨å‹¢: {convergence_info['description']}")
            
            # æ™‚é–“åˆ†æ
            print(f"\nâ° æ™‚é–“åˆ†æ:")
            print(f"   å–®epochå¹³å‡: {avg_epoch_time:.2f}s ({epochs_per_minute:.1f} epochs/min)")
            print(f"   éšæ®µå·²è€—æ™‚: {format_time(stage_elapsed)}")
            print(f"   éšæ®µé ä¼°å‰©é¤˜: {format_time(stage_eta)}")
            print(f"   éšæ®µç¸½é ä¼°: {format_time(stage_total_estimated)}")
            print(f"   ç´¯è¨ˆè¨“ç·´æ™‚é–“: {format_time(total_training_time)}")
            
            # ç³»çµ±ç‹€æ…‹
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated(self.device) / 1024**3
                memory_reserved = torch.cuda.memory_reserved(self.device) / 1024**3
                total_memory = torch.cuda.get_device_properties(self.device).total_memory / 1024**3
                memory_usage_percent = (memory_allocated / total_memory) * 100
                
                memory_status = "ğŸŸ¢ æ­£å¸¸" if memory_usage_percent < 70 else "ğŸŸ¡ ä¸­ç­‰" if memory_usage_percent < 85 else "ğŸ”´ é«˜"
                
                print(f"\nğŸ’¾ ç³»çµ±ç‹€æ…‹:")
                print(f"   GPUè¨˜æ†¶é«”: {memory_allocated:.2f}GB / {total_memory:.2f}GB ({memory_usage_percent:.1f}%) {memory_status}")
                print(f"   ä¿ç•™è¨˜æ†¶é«”: {memory_reserved:.2f}GB")
            
            # è¨“ç·´æ•ˆç‡æŒ‡æ¨™
            data_points_per_second = data_points / avg_epoch_time if avg_epoch_time > 0 else 0
            print(f"\nğŸš€ æ•ˆç‡æŒ‡æ¨™:")
            print(f"   è³‡æ–™è™•ç†é€Ÿåº¦: {data_points_per_second:,.0f} points/sec")
            
            # ç‰©ç†åƒæ•¸è¨ºæ–· - è¨ˆç®—ç­‰æ•ˆé›·è«¾æ•¸
            vis_t_mean = getattr(self, 'vis_t', torch.tensor(0.0)).mean().item()
            base_visc = 1.0/self.Re
            Re_eff = 1.0 / (base_visc + vis_t_mean) if vis_t_mean > 0 else self.Re
            vis_ratio = vis_t_mean / base_visc if base_visc > 0 else 0
            
            print(f"\nğŸ”¬ ç‰©ç†åƒæ•¸è¨ºæ–·:")
            print(f"   ç›®æ¨™é›·è«¾æ•¸: {self.Re}")
            print(f"   ç­‰æ•ˆé›·è«¾æ•¸: {Re_eff:.1f}")
            print(f"   Alpha EVM: {self.alpha_evm:.4f}")
            print(f"   EVMæ”¾å¤§å€æ•¸: {vis_ratio:.2f}x")
            if Re_eff < 1000:
                print(f"   âš ï¸  è­¦å‘Š: Re_efféä½å¯èƒ½å°è‡´Couetteæµ!")
            
            print(f"{'='*100}\n")
            
        else:
            # åˆå§‹å¹¾å€‹epochï¼Œè³‡è¨Šè¼ƒå°‘
            print(f"\n{'='*80}")
            print(f"ğŸ”¥ {self.current_stage} - åˆå§‹åŒ–éšæ®µ")
            print(f"   Epoch: {epoch_id + 1:,} / {num_epoch:,}")
            print(f"   å­¸ç¿’ç‡: {current_lr:.2e} | è³‡æ–™é»: {data_points:,}")
            print(f"   æå¤± - ç¸½: {loss:.3e} | æ–¹ç¨‹: {losses[0]:.3e} | ç›£ç£: {losses[2]:.3e} | é‚Šç•Œ: {losses[1]:.3e}")
            
            # ç‰©ç†åƒæ•¸è¨ºæ–· - è¨ˆç®—ç­‰æ•ˆé›·è«¾æ•¸
            vis_t_mean = getattr(self, 'vis_t', torch.tensor(0.0)).mean().item()
            base_visc = 1.0/self.Re
            Re_eff = 1.0 / (base_visc + vis_t_mean) if vis_t_mean > 0 else self.Re
            vis_ratio = vis_t_mean / base_visc if base_visc > 0 else 0
            
            print(f"   ğŸ”¬ Re_eff: {Re_eff:.1f} | Î±_EVM: {self.alpha_evm:.4f} | EVM: {vis_ratio:.1f}x")
            if Re_eff < 1000:
                print(f"   âš ï¸  è­¦å‘Š: Re_eff={Re_eff:.1f} éä½ï¼Œå¯èƒ½å°è‡´Couetteæµ!")
            
            print(f"   (æ™‚é–“é ä¼°å°‡åœ¨ç¬¬10å€‹epochå¾Œæä¾›)")
            print(f"{'='*80}\n")

    def _analyze_convergence_trend(self, current_losses):
        """åˆ†ææå¤±æ”¶æ–‚è¶¨å‹¢"""
        # å¦‚æœæ­·å²æ•¸æ“šä¸è¶³ï¼Œè¿”å›é»˜èªä¿¡æ¯
        if not hasattr(self, 'loss_history'):
            self.loss_history = []
        
        # è¨˜éŒ„ç•¶å‰æå¤±
        current_total_loss = current_losses[0] + current_losses[1]
        self.loss_history.append(current_total_loss)
        
        # ä¿æŒæœ€è¿‘100å€‹æå¤±è¨˜éŒ„
        if len(self.loss_history) > 100:
            self.loss_history = self.loss_history[-100:]
        
        if len(self.loss_history) < 10:
            return {"trend_symbol": "ğŸ“Š", "description": "æ”¶é›†æ•¸æ“šä¸­..."}
        
        # åˆ†ææœ€è¿‘çš„è¶¨å‹¢
        recent_losses = self.loss_history[-10:]
        earlier_losses = self.loss_history[-20:-10] if len(self.loss_history) >= 20 else self.loss_history[:-10]
        
        if len(earlier_losses) > 0:
            recent_avg = np.mean(recent_losses)
            earlier_avg = np.mean(earlier_losses)
            
            improvement_ratio = (earlier_avg - recent_avg) / earlier_avg if earlier_avg > 0 else 0
            
            if improvement_ratio > 0.1:
                return {"trend_symbol": "ğŸ“‰", "description": "å¿«é€Ÿæ”¶æ–‚ä¸­"}
            elif improvement_ratio > 0.01:
                return {"trend_symbol": "ğŸ“Š", "description": "ç©©å®šæ”¶æ–‚ä¸­"}
            elif improvement_ratio > -0.01:
                return {"trend_symbol": "â¡ï¸", "description": "ç·©æ…¢æ”¶æ–‚/å¹³ç©©"}
            else:
                return {"trend_symbol": "ğŸ“ˆ", "description": "å¯èƒ½ç™¼æ•£ï¼Œéœ€æ³¨æ„"}
        
        return {"trend_symbol": "ğŸ“Š", "description": "è¶¨å‹¢åˆ†æä¸­..."}

    def print_log_full_batch(self, loss, losses, epoch_id, num_epoch, data_points):
        current_lr = self.opt.param_groups[0]['lr']
        print('current lr is {}'.format(current_lr))
        print('epoch/num_epoch: {:6d} / {:d} data_points: {:d} avg_loss[Adam]: {:.3e} avg_eq_combined_loss: {:.3e} avg_bc_loss: {:.3e} avg_sup_loss: {:.3e} avg_eq1_loss: {:.3e} avg_eq2_loss: {:.3e} avg_eq3_loss: {:.3e} avg_eq4_loss: {:.3e}'.format(
            epoch_id + 1, num_epoch, data_points, loss, losses[0], losses[1], losses[2], losses[3], losses[4], losses[5], losses[6]))

    def print_log_batch(self, loss, losses, epoch_id, num_epoch, batch_size, steps_per_epoch):
        def get_lr(optimizer):
            for param_group in optimizer.param_groups:
                return param_group['lr']

        coverage_percent = 100.0  # å¾ªç’°è¦†è“‹ç¢ºä¿100%è¦†è“‹
        print("current lr is {}".format(get_lr(self.opt)))
        print("epoch/num_epoch: ", epoch_id + 1, "/", num_epoch,
              "batch_size:", batch_size,
              "steps/epoch:", steps_per_epoch,
              "coverage: {:.1f}%".format(coverage_percent),
              "avg_loss[Adam]: %.3e" %(loss),
              "avg_eq_combined_loss: %.3e" %(losses[0] if len(losses) > 0 else 0),
              "avg_bc_loss: %.3e" %(losses[1] if len(losses) > 1 else 0),
              "avg_sup_loss: %.3e" %(losses[2] if len(losses) > 2 else 0),
              "avg_eq1_loss: %.3e" %(losses[3] if len(losses) > 3 else 0),
              "avg_eq2_loss: %.3e" %(losses[4] if len(losses) > 4 else 0),
              "avg_eq3_loss: %.3e" %(losses[5] if len(losses) > 5 else 0),
              "avg_eq4_loss: %.3e" %(losses[6] if len(losses) > 6 else 0))

    def print_log(self, loss, losses, epoch_id, num_epoch):
        def get_lr(optimizer):
            for param_group in optimizer.param_groups:
                return param_group['lr']

        print("current lr is {}".format(get_lr(self.opt)))
        print("epoch/num_epoch: ", epoch_id + 1, "/", num_epoch,
              "loss[Adam]: %.3e" %(loss.detach().cpu().item()),
              "eq_combined_loss: %.3e" %(losses[0]),
              "bc_loss: %.3e" %(losses[1]),
              "sup_loss: %.3e" %(losses[2]),
              "eq1_loss: %.3e" %(losses[3]),
              "eq2_loss: %.3e" %(losses[4]),
              "eq3_loss: %.3e" %(losses[5]),
              "eq4_loss: %.3e" %(losses[6]))

    def evaluate(self, x, y, u, v, p):
        """ testing all points in the domain """
        x_test = x.reshape(-1,1)
        y_test = y.reshape(-1,1)
        u_test = u.reshape(-1,1)
        v_test = v.reshape(-1,1)
        p_test = p.reshape(-1,1)

        x_test = torch.tensor(x_test).float().to(self.device)
        y_test = torch.tensor(y_test).float().to(self.device)
        u_pred, v_pred, p_pred, _= self.neural_net_u(x_test, y_test)
        u_pred = u_pred.detach().cpu().numpy().reshape(-1,1)
        v_pred = v_pred.detach().cpu().numpy().reshape(-1,1)
        p_pred = p_pred.detach().cpu().numpy().reshape(-1,1)
        
        mask_p = ~np.isnan(p_test)
        # Error
        error_u = 100*np.linalg.norm(u_test-u_pred,2)/np.linalg.norm(u_test,2)
        error_v = 100*np.linalg.norm(v_test-v_pred,2)/np.linalg.norm(v_test,2)
        error_p = 100*np.linalg.norm(p_test[mask_p]-p_pred[mask_p], 2) / np.linalg.norm(p_test[mask_p], 2)
        if self.rank == 0:
            print('------------------------')
            print('Error u: %.2f %%' % (error_u))
            print('Error v: %.2f %%' % (error_v))
            print('Error p: %.2f %%' % (error_p))

    def test(self, x, y, u, v, p, loop=None, custom_save_dir=None):
        """ testing all points in the domain """
        x_test = x.reshape(-1,1)
        y_test = y.reshape(-1,1)
        u_test = u.reshape(-1,1)
        v_test = v.reshape(-1,1)
        p_test = p.reshape(-1,1)
        # Prediction
        x_test = torch.tensor(x_test).float().to(self.device)
        y_test = torch.tensor(y_test).float().to(self.device)
        u_pred, v_pred, p_pred, e_pred= self.neural_net_u(x_test, y_test)
        u_pred = u_pred.detach().cpu().numpy().reshape(-1,1)
        v_pred = v_pred.detach().cpu().numpy().reshape(-1,1)
        p_pred = p_pred.detach().cpu().numpy().reshape(-1,1)
        e_pred = e_pred.detach().cpu().numpy().reshape(-1,1)
        
        mask_p = ~np.isnan(p_test)
        # Error
        error_u = 100*np.linalg.norm(u_test-u_pred,2)/np.linalg.norm(u_test,2)
        error_v = 100*np.linalg.norm(v_test-v_pred,2)/np.linalg.norm(v_test,2)
        error_p = 100*np.linalg.norm(p_test[mask_p]-p_pred[mask_p], 2) / np.linalg.norm(p_test[mask_p], 2)
        if self.rank == 0:
            print('------------------------')
            print('Error u: %.3f %%' % (error_u))
            print('Error v: %.3f %%' % (error_v))
            print('Error p: %.3f %%' % (error_p))
            print('------------------------')

            u_pred = u_pred.reshape(257,257)
            v_pred = v_pred.reshape(257,257)
            p_pred = p_pred.reshape(257,257)
            e_pred = e_pred.reshape(257,257)

            Re_folder = 'Re'+str(self.Re)
            NNsize = str(self.layers) + 'x' + str(self.hidden_size) + '_Nf'+str(np.int32(self.N_f/1000)) + 'k'
            lambdas = 'lamB'+str(self.alpha_b) + '_alpha'+str(self.alpha_evm) + str(self.current_stage)
            
            if custom_save_dir:
                # ä½¿ç”¨è‡ªå®šç¾©ä¿å­˜ç›®éŒ„
                relative_path = custom_save_dir
                filename = f'test_result_epoch_{loop:07d}.mat'  # 7ä½æ•¸å­—ï¼Œæ–¹ä¾¿æ’åº
            else:
                # ä½¿ç”¨åŸä¾†çš„é‚è¼¯
                # å¾config.pyè®€å–åŸºç¤è·¯å¾‘
                try:
                    from config import RESULTS_PATH
                    base_path = RESULTS_PATH
                except ImportError:
                    base_path = 'results'

                relative_path = os.path.join(base_path, Re_folder, f"{NNsize}_{lambdas}")
                filename = f'cavity_result_loop_{loop}.mat'

            if not os.path.exists(relative_path):
                os.makedirs(relative_path, exist_ok=True)

            file_path = os.path.join(relative_path, filename)

            scipy.io.savemat(file_path,
                        {'U_pred':u_pred,
                         'V_pred':v_pred,
                         'P_pred':p_pred,
                         'E_pred':e_pred,
                         'error_u':error_u,
                         'error_v':error_v,
                         'error_p':error_p,
                         'lam_bcs':self.alpha_b,
                         'lam_equ':self.alpha_e,
                         'global_epoch':loop,  # æ·»åŠ å…¨å±€epochä¿¡æ¯
                         'stage_info': getattr(self, 'current_stage', 'unknown')})  # æ·»åŠ stageä¿¡æ¯

    def save(self, filename, directory=None, N_HLayer=None, N_neu=None, N_f=None):
        Re_folder = 'Re'+str(self.Re)
        NNsize = str(N_HLayer) + 'x' + str(N_neu) + '_Nf'+str(np.int32(N_f/1000)) + 'k'
        lambdas = 'lamB'+str(self.alpha_b) + '_alpha'+str(self.alpha_evm) + str(self.current_stage)

        relative_path = '/results/' +  Re_folder + '/' + NNsize + '_' + lambdas + '/'

        if not directory:
            directory = os.getcwd()
        save_results_to = directory + relative_path
        if not os.path.exists(save_results_to):
            os.makedirs(save_results_to)

        # Save model state dict without DDP wrapper
        torch.save(self.get_model(self.net).state_dict(), save_results_to+filename)
        torch.save(self.get_model(self.net_1).state_dict(), save_results_to+filename+'_evm')

    def divergence(self, x_star, y_star):
        (self.eq1_pred, self.eq2_pred,
         self.eq3_pred, self.eq4_pred) = self.neural_net_equations(x_star, y_star)
        div = self.eq3_pred
        return div
