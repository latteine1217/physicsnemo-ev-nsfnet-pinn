#!/usr/bin/env python3
"""
LDC-PINNs: Physics-Informed Neural Networks for Lid-Driven Cavity Flow
åŸºæ–¼ NVIDIA PhysicsNeMo æ¡†æ¶å¯¦ç¾

This module implements a Physics-Informed Neural Network (PINN) solution for the 
lid-driven cavity flow problem using PhysicsNeMo framework with symbolic PDE definitions.
"""

import os
import sys
import torch
import hydra
from omegaconf import DictConfig
from physicsnemo.distributed import DistributedManager

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ° Python path  
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.ldc_pinn import LidDrivenCavityPINN
from data.cavity_datamodule import CavityDataModule
from utils.physics_loss import PhysicsLoss
from utils.logger import setup_logger


@hydra.main(version_base=None, config_path="configs", config_name="ldc_pinn")
def main(cfg: DictConfig) -> None:
    """
    ä¸»è¨“ç·´å‡½æ•¸ - ä½¿ç”¨PhysicsNeMoæ¡†æ¶è¨“ç·´lid-driven cavity PINNæ¨¡å‹
    
    Args:
        cfg: Hydraé…ç½®å°è±¡
    """
    # åˆå§‹åŒ–åˆ†å¸ƒå¼ç®¡ç†å™¨ (PhysicsNeMoçš„åˆ†å¸ƒå¼åŠŸèƒ½)
    DistributedManager.initialize()
    dist = DistributedManager()
    
    # è¨­ç½®æ—¥èªŒ
    logger = setup_logger(cfg.logging)
    
    if dist.rank == 0:
        logger.info("ğŸš€ é–‹å§‹PhysicsNeMo LDC-PINNè¨“ç·´")
        logger.info(f"ğŸ“Š ä½¿ç”¨è¨­å‚™: {dist.device}")
        logger.info(f"ğŸ”§ åˆ†å¸ƒå¼è¨­ç½®: {dist.world_size} GPUs")
    
    # è¨­ç½®CUDAå„ªåŒ– (Tesla P100ç›¸å®¹æ€§)
    if cfg.optimization.torch_compile and hasattr(torch, 'compile'):
        try:
            # æª¢æŸ¥CUDA capability
            if torch.cuda.is_available():
                capability = torch.cuda.get_device_capability(dist.local_rank)
                if capability[0] < 7:  # P100æ˜¯6.0
                    logger.warning("âš ï¸  Tesla P100æª¢æ¸¬åˆ°ï¼Œç¦ç”¨torch.compile")
                    cfg.optimization.torch_compile = False
        except Exception as e:
            logger.warning(f"âš ï¸  ç„¡æ³•æª¢æ¸¬CUDA capability: {e}")
            cfg.optimization.torch_compile = False
    
    # åˆå§‹åŒ–è³‡æ–™æ¨¡çµ„
    datamodule = CavityDataModule(
        cfg=cfg.data,
        Re=cfg.physics.Re,
        device=dist.device
    )
    
    # è¨­ç½®è³‡æ–™
    datamodule.setup()
    
    # åˆå§‹åŒ–PINNæ¨¡å‹ (ä½¿ç”¨PhysicsNeMoæ¶æ§‹)
    model = LidDrivenCavityPINN(
        cfg=cfg.model,
        physics_cfg=cfg.physics,
        device=dist.device
    )
    
    # è¨­ç½®ç‰©ç†æå¤±è¨ˆç®—
    physics_loss = PhysicsLoss(
        cfg=cfg.physics,
        Re=cfg.physics.Re,
        device=dist.device
    )
    
    # åˆ†å¸ƒå¼æ¨¡å‹åŒ…è£
    if dist.distributed:
        from torch.nn.parallel import DistributedDataParallel as DDP
        model = DDP(
            model,
            device_ids=[dist.local_rank],
            output_device=dist.device,
            broadcast_buffers=dist.broadcast_buffers,
            find_unused_parameters=dist.find_unused_parameters,
        )
    
    # å„ªåŒ–å™¨è¨­ç½®
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=cfg.training.learning_rate,
        weight_decay=cfg.training.weight_decay
    )
    
    # åŸ·è¡Œè¨“ç·´å¾ªç’°
    from trainers.physics_trainer import PhysicsTrainer
    
    trainer = PhysicsTrainer(
        model=model,
        optimizer=optimizer,
        physics_loss=physics_loss,
        datamodule=datamodule,
        cfg=cfg.training,
        logger=logger,
        device=dist.device
    )
    
    # é–‹å§‹è¨“ç·´
    trainer.fit()
    
    if dist.rank == 0:
        logger.info("ğŸ‰ è¨“ç·´å®Œæˆ!")


if __name__ == "__main__":
    main()